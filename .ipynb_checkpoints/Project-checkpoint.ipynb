{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "69dd98a2-3056-4b96-92de-6ae65b4615f7",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ca1ba27ee5dccc87a9699e0a5c8e7243",
     "grade": false,
     "grade_id": "cell-91c6bfec02a2afea",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Notebook : EEG signals classification using Pretrained Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e71d702e-1043-42f8-918f-53bb0e758e19",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "9757acb6786f9fa0bf81b4306de692b0",
     "grade": false,
     "grade_id": "cell-2421e722311d69f3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "The goal of this practical course is to decode information from an non-invasive cerebral signal : Electroencephalogram (EEG). To this aim, we are going to implement a classification task using a model based on the GPT (Generative Pre-Trained Tranformers) architecture. This model has been Pretrained on a large amount of EEG data. Our goal today is to finetune this model to use it as an EEG classifier. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8c1f63b0-2fdd-4141-a1e1-ea6758ab729a",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "53586b6996837c1f6ba77a361c150891",
     "grade": false,
     "grade_id": "cell-b63964217272e1ef",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting numpy==1.26.3\n",
      "  Using cached numpy-1.26.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
      "Requirement already satisfied: torch==2.8.0 in /opt/micromamba/lib/python3.11/site-packages (2.8.0)\n",
      "Collecting scikit-learn==1.6.1\n",
      "  Using cached scikit_learn-1.6.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\n",
      "Collecting pandas==2.3.3\n",
      "  Using cached pandas-2.3.3-cp311-cp311-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (91 kB)\n",
      "Collecting matplotlib==3.9.4\n",
      "  Using cached matplotlib-3.9.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
      "Collecting transformers==4.29.2\n",
      "  Using cached transformers-4.29.2-py3-none-any.whl.metadata (112 kB)\n",
      "Requirement already satisfied: filelock in /opt/micromamba/lib/python3.11/site-packages (from torch==2.8.0) (3.19.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /opt/micromamba/lib/python3.11/site-packages (from torch==2.8.0) (4.15.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /opt/micromamba/lib/python3.11/site-packages (from torch==2.8.0) (1.14.0)\n",
      "Requirement already satisfied: networkx in /opt/micromamba/lib/python3.11/site-packages (from torch==2.8.0) (3.5)\n",
      "Requirement already satisfied: jinja2 in /opt/micromamba/lib/python3.11/site-packages (from torch==2.8.0) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /opt/micromamba/lib/python3.11/site-packages (from torch==2.8.0) (2025.9.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in /opt/micromamba/lib/python3.11/site-packages (from torch==2.8.0) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in /opt/micromamba/lib/python3.11/site-packages (from torch==2.8.0) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in /opt/micromamba/lib/python3.11/site-packages (from torch==2.8.0) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /opt/micromamba/lib/python3.11/site-packages (from torch==2.8.0) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in /opt/micromamba/lib/python3.11/site-packages (from torch==2.8.0) (12.8.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in /opt/micromamba/lib/python3.11/site-packages (from torch==2.8.0) (11.3.3.83)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in /opt/micromamba/lib/python3.11/site-packages (from torch==2.8.0) (10.3.9.90)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in /opt/micromamba/lib/python3.11/site-packages (from torch==2.8.0) (11.7.3.90)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in /opt/micromamba/lib/python3.11/site-packages (from torch==2.8.0) (12.5.8.93)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /opt/micromamba/lib/python3.11/site-packages (from torch==2.8.0) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /opt/micromamba/lib/python3.11/site-packages (from torch==2.8.0) (2.27.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /opt/micromamba/lib/python3.11/site-packages (from torch==2.8.0) (12.8.90)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /opt/micromamba/lib/python3.11/site-packages (from torch==2.8.0) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /opt/micromamba/lib/python3.11/site-packages (from torch==2.8.0) (1.13.1.3)\n",
      "Requirement already satisfied: triton==3.4.0 in /opt/micromamba/lib/python3.11/site-packages (from torch==2.8.0) (3.4.0)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /opt/micromamba/lib/python3.11/site-packages (from scikit-learn==1.6.1) (1.16.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /opt/micromamba/lib/python3.11/site-packages (from scikit-learn==1.6.1) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /opt/micromamba/lib/python3.11/site-packages (from scikit-learn==1.6.1) (3.6.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/micromamba/lib/python3.11/site-packages (from pandas==2.3.3) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/micromamba/lib/python3.11/site-packages (from pandas==2.3.3) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/micromamba/lib/python3.11/site-packages (from pandas==2.3.3) (2025.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/micromamba/lib/python3.11/site-packages (from matplotlib==3.9.4) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/micromamba/lib/python3.11/site-packages (from matplotlib==3.9.4) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/micromamba/lib/python3.11/site-packages (from matplotlib==3.9.4) (4.60.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/micromamba/lib/python3.11/site-packages (from matplotlib==3.9.4) (1.4.9)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/micromamba/lib/python3.11/site-packages (from matplotlib==3.9.4) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in /opt/micromamba/lib/python3.11/site-packages (from matplotlib==3.9.4) (11.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/micromamba/lib/python3.11/site-packages (from matplotlib==3.9.4) (3.2.5)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /opt/micromamba/lib/python3.11/site-packages (from transformers==4.29.2) (0.35.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/micromamba/lib/python3.11/site-packages (from transformers==4.29.2) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/micromamba/lib/python3.11/site-packages (from transformers==4.29.2) (2025.9.18)\n",
      "Requirement already satisfied: requests in /opt/micromamba/lib/python3.11/site-packages (from transformers==4.29.2) (2.32.5)\n",
      "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers==4.29.2)\n",
      "  Using cached tokenizers-0.13.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/micromamba/lib/python3.11/site-packages (from transformers==4.29.2) (4.67.1)\n",
      "Requirement already satisfied: setuptools>=40.8.0 in /opt/micromamba/lib/python3.11/site-packages (from triton==3.4.0->torch==2.8.0) (80.9.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /opt/micromamba/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.14.1->transformers==4.29.2) (1.1.10)\n",
      "Requirement already satisfied: six>=1.5 in /opt/micromamba/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas==2.3.3) (1.16.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/micromamba/lib/python3.11/site-packages (from sympy>=1.13.3->torch==2.8.0) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/micromamba/lib/python3.11/site-packages (from jinja2->torch==2.8.0) (3.0.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/micromamba/lib/python3.11/site-packages (from requests->transformers==4.29.2) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/micromamba/lib/python3.11/site-packages (from requests->transformers==4.29.2) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/micromamba/lib/python3.11/site-packages (from requests->transformers==4.29.2) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/micromamba/lib/python3.11/site-packages (from requests->transformers==4.29.2) (2025.8.3)\n",
      "Using cached numpy-1.26.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
      "Using cached scikit_learn-1.6.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.5 MB)\n",
      "Using cached pandas-2.3.3-cp311-cp311-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (12.8 MB)\n",
      "Using cached matplotlib-3.9.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.3 MB)\n",
      "Using cached transformers-4.29.2-py3-none-any.whl (7.1 MB)\n",
      "Using cached tokenizers-0.13.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
      "Installing collected packages: tokenizers, numpy, pandas, transformers, scikit-learn, matplotlib\n",
      "\u001b[2K  Attempting uninstall: tokenizers\n",
      "\u001b[2K    Found existing installation: tokenizers 0.22.1\n",
      "\u001b[2K    Uninstalling tokenizers-0.22.1:\n",
      "\u001b[2K      Successfully uninstalled tokenizers-0.22.1\n",
      "\u001b[2K  Attempting uninstall: numpy\n",
      "\u001b[2K    Found existing installation: numpy 1.26.4━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1/6\u001b[0m [numpy]\n",
      "\u001b[2K    Uninstalling numpy-1.26.4:━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1/6\u001b[0m [numpy]\n",
      "\u001b[2K      Successfully uninstalled numpy-1.26.4━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1/6\u001b[0m [numpy]\n",
      "\u001b[2K  Attempting uninstall: pandas90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1/6\u001b[0m [numpy]\n",
      "\u001b[2K    Found existing installation: pandas 2.3.2━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1/6\u001b[0m [numpy]\n",
      "\u001b[2K    Uninstalling pandas-2.3.2:╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2/6\u001b[0m [pandas]\n",
      "\u001b[2K      Successfully uninstalled pandas-2.3.2━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2/6\u001b[0m [pandas]\n",
      "\u001b[2K  Attempting uninstall: transformers[90m━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2/6\u001b[0m [pandas]\n",
      "\u001b[2K    Found existing installation: transformers 4.56.2━━━━━━━━━━\u001b[0m \u001b[32m2/6\u001b[0m [pandas]\n",
      "\u001b[2K    Uninstalling transformers-4.56.2:╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3/6\u001b[0m [transformers]\n",
      "\u001b[2K      Successfully uninstalled transformers-4.56.2━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3/6\u001b[0m [transformers]\n",
      "\u001b[2K  Attempting uninstall: scikit-learnm╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3/6\u001b[0m [transformers]\n",
      "\u001b[2K    Found existing installation: scikit-learn 1.7.20m━━━━━━━━━━━━━\u001b[0m \u001b[32m4/6\u001b[0m [scikit-learn]\n",
      "\u001b[2K    Uninstalling scikit-learn-1.7.2:91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━\u001b[0m \u001b[32m4/6\u001b[0m [scikit-learn]\n",
      "\u001b[2K      Successfully uninstalled scikit-learn-1.7.2[90m━━━━━━━━━━━━━\u001b[0m \u001b[32m4/6\u001b[0m [scikit-learn]\n",
      "\u001b[2K  Attempting uninstall: matplotlib\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━\u001b[0m \u001b[32m4/6\u001b[0m [scikit-learn]\n",
      "\u001b[2K    Found existing installation: matplotlib 3.10.6━━━━━━━━━━━━\u001b[0m \u001b[32m4/6\u001b[0m [scikit-learn]\n",
      "\u001b[2K    Uninstalling matplotlib-3.10.6:━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━\u001b[0m \u001b[32m5/6\u001b[0m [matplotlib]\n",
      "\u001b[2K      Successfully uninstalled matplotlib-3.10.60m╺\u001b[0m\u001b[90m━━━━━━\u001b[0m \u001b[32m5/6\u001b[0m [matplotlib]\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6/6\u001b[0m [matplotlib]6\u001b[0m [matplotlib]\n",
      "\u001b[1A\u001b[2K\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "jax 0.7.2 requires numpy>=2.0, but you have numpy 1.26.3 which is incompatible.\n",
      "jaxlib 0.7.2 requires numpy>=2.0, but you have numpy 1.26.3 which is incompatible.\n",
      "tetgen 0.6.7 requires numpy<3,>=2, but you have numpy 1.26.3 which is incompatible.\n",
      "obspy 1.4.2 requires sqlalchemy<2, but you have sqlalchemy 2.0.43 which is incompatible.\n",
      "pytesmo 0.18.0 requires numpy>=2.0, but you have numpy 1.26.3 which is incompatible.\n",
      "pgcore 1.5.4 requires numpy>=2.1, but you have numpy 1.26.3 which is incompatible.\n",
      "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.3 which is incompatible.\n",
      "opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.3 which is incompatible.\n",
      "pygimli 1.5.4 requires numpy>=2.1, but you have numpy 1.26.3 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed matplotlib-3.9.4 numpy-1.26.3 pandas-2.3.3 scikit-learn-1.6.1 tokenizers-0.13.3 transformers-4.29.2\n",
      "Collecting accelerate\n",
      "  Using cached accelerate-1.12.0-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/micromamba/lib/python3.11/site-packages (from accelerate) (1.26.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/micromamba/lib/python3.11/site-packages (from accelerate) (25.0)\n",
      "Requirement already satisfied: psutil in /opt/micromamba/lib/python3.11/site-packages (from accelerate) (6.1.1)\n",
      "Requirement already satisfied: pyyaml in /opt/micromamba/lib/python3.11/site-packages (from accelerate) (6.0.2)\n",
      "Requirement already satisfied: torch>=2.0.0 in /opt/micromamba/lib/python3.11/site-packages (from accelerate) (2.8.0)\n",
      "Requirement already satisfied: huggingface_hub>=0.21.0 in /opt/micromamba/lib/python3.11/site-packages (from accelerate) (0.35.0)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /opt/micromamba/lib/python3.11/site-packages (from accelerate) (0.6.2)\n",
      "Requirement already satisfied: filelock in /opt/micromamba/lib/python3.11/site-packages (from huggingface_hub>=0.21.0->accelerate) (3.19.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/micromamba/lib/python3.11/site-packages (from huggingface_hub>=0.21.0->accelerate) (2025.9.0)\n",
      "Requirement already satisfied: requests in /opt/micromamba/lib/python3.11/site-packages (from huggingface_hub>=0.21.0->accelerate) (2.32.5)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /opt/micromamba/lib/python3.11/site-packages (from huggingface_hub>=0.21.0->accelerate) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/micromamba/lib/python3.11/site-packages (from huggingface_hub>=0.21.0->accelerate) (4.15.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /opt/micromamba/lib/python3.11/site-packages (from huggingface_hub>=0.21.0->accelerate) (1.1.10)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /opt/micromamba/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (1.14.0)\n",
      "Requirement already satisfied: networkx in /opt/micromamba/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (3.5)\n",
      "Requirement already satisfied: jinja2 in /opt/micromamba/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (3.1.6)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in /opt/micromamba/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in /opt/micromamba/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in /opt/micromamba/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /opt/micromamba/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in /opt/micromamba/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (12.8.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in /opt/micromamba/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (11.3.3.83)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in /opt/micromamba/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (10.3.9.90)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in /opt/micromamba/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (11.7.3.90)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in /opt/micromamba/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (12.5.8.93)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /opt/micromamba/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /opt/micromamba/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (2.27.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /opt/micromamba/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (12.8.90)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /opt/micromamba/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /opt/micromamba/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (1.13.1.3)\n",
      "Requirement already satisfied: triton==3.4.0 in /opt/micromamba/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (3.4.0)\n",
      "Requirement already satisfied: setuptools>=40.8.0 in /opt/micromamba/lib/python3.11/site-packages (from triton==3.4.0->torch>=2.0.0->accelerate) (80.9.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/micromamba/lib/python3.11/site-packages (from sympy>=1.13.3->torch>=2.0.0->accelerate) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/micromamba/lib/python3.11/site-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/micromamba/lib/python3.11/site-packages (from requests->huggingface_hub>=0.21.0->accelerate) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/micromamba/lib/python3.11/site-packages (from requests->huggingface_hub>=0.21.0->accelerate) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/micromamba/lib/python3.11/site-packages (from requests->huggingface_hub>=0.21.0->accelerate) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/micromamba/lib/python3.11/site-packages (from requests->huggingface_hub>=0.21.0->accelerate) (2025.8.3)\n",
      "Using cached accelerate-1.12.0-py3-none-any.whl (380 kB)\n",
      "Installing collected packages: accelerate\n",
      "Successfully installed accelerate-1.12.0\n",
      "Collecting transformers==4.29.2\n",
      "  Using cached transformers-4.29.2-py3-none-any.whl.metadata (112 kB)\n",
      "Collecting filelock (from transformers==4.29.2)\n",
      "  Using cached filelock-3.20.3-py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting huggingface-hub<1.0,>=0.14.1 (from transformers==4.29.2)\n",
      "  Using cached huggingface_hub-0.36.0-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting numpy>=1.17 (from transformers==4.29.2)\n",
      "  Using cached numpy-2.4.1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (6.6 kB)\n",
      "Collecting packaging>=20.0 (from transformers==4.29.2)\n",
      "  Using cached packaging-25.0-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting pyyaml>=5.1 (from transformers==4.29.2)\n",
      "  Using cached pyyaml-6.0.3-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (2.4 kB)\n",
      "Collecting regex!=2019.12.17 (from transformers==4.29.2)\n",
      "  Using cached regex-2026.1.15-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (40 kB)\n",
      "Collecting requests (from transformers==4.29.2)\n",
      "  Using cached requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\n",
      "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers==4.29.2)\n",
      "  Using cached tokenizers-0.13.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Collecting tqdm>=4.27 (from transformers==4.29.2)\n",
      "  Using cached tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting fsspec>=2023.5.0 (from huggingface-hub<1.0,>=0.14.1->transformers==4.29.2)\n",
      "  Using cached fsspec-2026.1.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting typing-extensions>=3.7.4.3 (from huggingface-hub<1.0,>=0.14.1->transformers==4.29.2)\n",
      "  Using cached typing_extensions-4.15.0-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting hf-xet<2.0.0,>=1.1.3 (from huggingface-hub<1.0,>=0.14.1->transformers==4.29.2)\n",
      "  Using cached hf_xet-1.2.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
      "Collecting charset_normalizer<4,>=2 (from requests->transformers==4.29.2)\n",
      "  Using cached charset_normalizer-3.4.4-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (37 kB)\n",
      "Collecting idna<4,>=2.5 (from requests->transformers==4.29.2)\n",
      "  Using cached idna-3.11-py3-none-any.whl.metadata (8.4 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests->transformers==4.29.2)\n",
      "  Using cached urllib3-2.6.3-py3-none-any.whl.metadata (6.9 kB)\n",
      "Collecting certifi>=2017.4.17 (from requests->transformers==4.29.2)\n",
      "  Using cached certifi-2026.1.4-py3-none-any.whl.metadata (2.5 kB)\n",
      "Using cached transformers-4.29.2-py3-none-any.whl (7.1 MB)\n",
      "Using cached huggingface_hub-0.36.0-py3-none-any.whl (566 kB)\n",
      "Using cached hf_xet-1.2.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n",
      "Using cached tokenizers-0.13.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
      "Using cached fsspec-2026.1.0-py3-none-any.whl (201 kB)\n",
      "Using cached numpy-2.4.1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (16.7 MB)\n",
      "Using cached packaging-25.0-py3-none-any.whl (66 kB)\n",
      "Using cached pyyaml-6.0.3-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (806 kB)\n",
      "Using cached regex-2026.1.15-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (800 kB)\n",
      "Using cached tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Using cached typing_extensions-4.15.0-py3-none-any.whl (44 kB)\n",
      "Using cached filelock-3.20.3-py3-none-any.whl (16 kB)\n",
      "Using cached requests-2.32.5-py3-none-any.whl (64 kB)\n",
      "Using cached charset_normalizer-3.4.4-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (151 kB)\n",
      "Using cached idna-3.11-py3-none-any.whl (71 kB)\n",
      "Using cached urllib3-2.6.3-py3-none-any.whl (131 kB)\n",
      "Using cached certifi-2026.1.4-py3-none-any.whl (152 kB)\n",
      "Installing collected packages: tokenizers, urllib3, typing-extensions, tqdm, regex, pyyaml, packaging, numpy, idna, hf-xet, fsspec, filelock, charset_normalizer, certifi, requests, huggingface-hub, transformers\n",
      "\u001b[2K  Attempting uninstall: tokenizers\n",
      "\u001b[2K    Found existing installation: tokenizers 0.13.3\n",
      "\u001b[2K    Uninstalling tokenizers-0.13.3:\n",
      "\u001b[2K      Successfully uninstalled tokenizers-0.13.3\n",
      "\u001b[2K  Attempting uninstall: urllib3\n",
      "\u001b[2K    Found existing installation: urllib3 2.5.0\n",
      "\u001b[2K    Uninstalling urllib3-2.5.0:\n",
      "\u001b[2K      Successfully uninstalled urllib3-2.5.0━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 1/17\u001b[0m [urllib3]\n",
      "\u001b[2K  Attempting uninstall: typing-extensions━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 1/17\u001b[0m [urllib3]\n",
      "\u001b[2K    Found existing installation: typing_extensions 4.15.0━━━━━\u001b[0m \u001b[32m 1/17\u001b[0m [urllib3]\n",
      "\u001b[2K    Uninstalling typing_extensions-4.15.0:━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 1/17\u001b[0m [urllib3]\n",
      "\u001b[2K      Successfully uninstalled typing_extensions-4.15.0━━━━━━━━━━━\u001b[0m \u001b[32m 2/17\u001b[0m [typing-extensions]\n",
      "\u001b[2K  Attempting uninstall: tqdm━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 2/17\u001b[0m [typing-extensions]\n",
      "\u001b[2K    Found existing installation: tqdm 4.67.1━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 2/17\u001b[0m [typing-extensions]\n",
      "\u001b[2K    Uninstalling tqdm-4.67.1:━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 2/17\u001b[0m [typing-extensions]\n",
      "\u001b[2K      Successfully uninstalled tqdm-4.67.1━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 2/17\u001b[0m [typing-extensions]\n",
      "\u001b[2K  Attempting uninstall: regex━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 2/17\u001b[0m [typing-extensions]\n",
      "\u001b[2K    Found existing installation: regex 2025.9.18━━━━━━━━━━━━━━\u001b[0m \u001b[32m 2/17\u001b[0m [typing-extensions]\n",
      "\u001b[2K    Uninstalling regex-2025.9.18:━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 2/17\u001b[0m [typing-extensions]\n",
      "\u001b[2K      Successfully uninstalled regex-2025.9.18━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 2/17\u001b[0m [typing-extensions]\n",
      "\u001b[2K  Attempting uninstall: pyyamlm\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 4/17\u001b[0m [regex]ensions]\n",
      "\u001b[2K    Found existing installation: PyYAML 6.0.2━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 4/17\u001b[0m [regex]\n",
      "\u001b[2K    Uninstalling PyYAML-6.0.2:0m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 4/17\u001b[0m [regex]\n",
      "\u001b[2K      Successfully uninstalled PyYAML-6.0.2━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 4/17\u001b[0m [regex]\n",
      "\u001b[2K  Attempting uninstall: packaging━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 4/17\u001b[0m [regex]\n",
      "\u001b[2K    Found existing installation: packaging 25.0━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 4/17\u001b[0m [regex]\n",
      "\u001b[2K    Uninstalling packaging-25.0:━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 4/17\u001b[0m [regex]\n",
      "\u001b[2K      Successfully uninstalled packaging-25.0━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 4/17\u001b[0m [regex]\n",
      "\u001b[2K  Attempting uninstall: numpy0m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 6/17\u001b[0m [packaging]\n",
      "\u001b[2K    Found existing installation: numpy 1.26.3━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 6/17\u001b[0m [packaging]\n",
      "\u001b[2K    Uninstalling numpy-1.26.3:0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 6/17\u001b[0m [packaging]\n",
      "\u001b[2K      Successfully uninstalled numpy-1.26.3━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 6/17\u001b[0m [packaging]\n",
      "\u001b[2K  Attempting uninstall: idna\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 7/17\u001b[0m [numpy]\n",
      "\u001b[2K    Found existing installation: idna 3.10━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 7/17\u001b[0m [numpy]\n",
      "\u001b[2K    Uninstalling idna-3.10:0m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 7/17\u001b[0m [numpy]\n",
      "\u001b[2K      Successfully uninstalled idna-3.10━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 7/17\u001b[0m [numpy]\n",
      "\u001b[2K  Attempting uninstall: hf-xet\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 8/17\u001b[0m [idna]\n",
      "\u001b[2K    Found existing installation: hf-xet 1.1.10━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 8/17\u001b[0m [idna]\n",
      "\u001b[2K    Uninstalling hf-xet-1.1.10:╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 8/17\u001b[0m [idna]\n",
      "\u001b[2K      Successfully uninstalled hf-xet-1.1.10━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 8/17\u001b[0m [idna]\n",
      "\u001b[2K  Attempting uninstall: fsspecm╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 8/17\u001b[0m [idna]\n",
      "\u001b[2K    Found existing installation: fsspec 2025.9.0━━━━━━━━━━━━━━\u001b[0m \u001b[32m 8/17\u001b[0m [idna]\n",
      "\u001b[2K    Uninstalling fsspec-2025.9.0:[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 8/17\u001b[0m [idna]\n",
      "\u001b[2K      Successfully uninstalled fsspec-2025.9.0━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 8/17\u001b[0m [idna]\n",
      "\u001b[2K  Attempting uninstall: filelock[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10/17\u001b[0m [fsspec]\n",
      "\u001b[2K    Found existing installation: filelock 3.19.1━━━━━━━━━━━━━━\u001b[0m \u001b[32m10/17\u001b[0m [fsspec]\n",
      "\u001b[2K    Uninstalling filelock-3.19.1:91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10/17\u001b[0m [fsspec]\n",
      "\u001b[2K      Successfully uninstalled filelock-3.19.1━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10/17\u001b[0m [fsspec]\n",
      "\u001b[2K  Attempting uninstall: charset_normalizer[90m━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10/17\u001b[0m [fsspec]\n",
      "\u001b[2K    Found existing installation: charset-normalizer 3.4.3━━━━━\u001b[0m \u001b[32m10/17\u001b[0m [fsspec]\n",
      "\u001b[2K    Uninstalling charset-normalizer-3.4.3:[90m━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10/17\u001b[0m [fsspec]\n",
      "\u001b[2K      Successfully uninstalled charset-normalizer-3.4.3━━━━━━━\u001b[0m \u001b[32m10/17\u001b[0m [fsspec]\n",
      "\u001b[2K  Attempting uninstall: certifi━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━\u001b[0m \u001b[32m12/17\u001b[0m [charset_normalizer]\n",
      "\u001b[2K    Found existing installation: certifi 2025.8.30m━━━━━━━━━━━\u001b[0m \u001b[32m12/17\u001b[0m [charset_normalizer]\n",
      "\u001b[2K    Uninstalling certifi-2025.8.3:0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━\u001b[0m \u001b[32m12/17\u001b[0m [charset_normalizer]\n",
      "\u001b[2K      Successfully uninstalled certifi-2025.8.3[90m━━━━━━━━━━━\u001b[0m \u001b[32m12/17\u001b[0m [charset_normalizer]\n",
      "\u001b[2K  Attempting uninstall: requests\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━\u001b[0m \u001b[32m12/17\u001b[0m [charset_normalizer]\n",
      "\u001b[2K    Found existing installation: requests 2.32.590m━━━━━━━━━━━\u001b[0m \u001b[32m12/17\u001b[0m [charset_normalizer]\n",
      "\u001b[2K    Uninstalling requests-2.32.5:[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━\u001b[0m \u001b[32m12/17\u001b[0m [charset_normalizer]\n",
      "\u001b[2K      Successfully uninstalled requests-2.32.5\u001b[90m━━━━━━━━━━━\u001b[0m \u001b[32m12/17\u001b[0m [charset_normalizer]\n",
      "\u001b[2K  Attempting uninstall: huggingface-hub0m╺\u001b[0m\u001b[90m━━━━━━━━━━━\u001b[0m \u001b[32m12/17\u001b[0m [charset_normalizer]\n",
      "\u001b[2K    Found existing installation: huggingface-hub 0.35.0━━━━━━━\u001b[0m \u001b[32m12/17\u001b[0m [charset_normalizer]\n",
      "\u001b[2K    Uninstalling huggingface-hub-0.35.0:m╺\u001b[0m\u001b[90m━━━━━━━━━━━\u001b[0m \u001b[32m12/17\u001b[0m [charset_normalizer]\n",
      "\u001b[2K      Successfully uninstalled huggingface-hub-0.35.0━━━━━━━━━\u001b[0m \u001b[32m12/17\u001b[0m [charset_normalizer]\n",
      "\u001b[2K  Attempting uninstall: transformers━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━\u001b[0m \u001b[32m15/17\u001b[0m [huggingface-hub]\n",
      "\u001b[2K    Found existing installation: transformers 4.29.2m\u001b[90m━━━━\u001b[0m \u001b[32m15/17\u001b[0m [huggingface-hub]\n",
      "\u001b[2K    Uninstalling transformers-4.29.2:━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━\u001b[0m \u001b[32m16/17\u001b[0m [transformers]\n",
      "\u001b[2K      Successfully uninstalled transformers-4.29.2╸\u001b[0m\u001b[90m━━\u001b[0m \u001b[32m16/17\u001b[0m [transformers]\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17/17\u001b[0m [transformers][0m [transformers]\n",
      "\u001b[1A\u001b[2K\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "numba 0.62.0 requires numpy<2.4,>=1.22, but you have numpy 2.4.1 which is incompatible.\n",
      "obspy 1.4.2 requires sqlalchemy<2, but you have sqlalchemy 2.0.43 which is incompatible.\n",
      "jupytercad 3.1.7 requires jupyter-collaboration<4,>=3, but you have jupyter-collaboration 4.1.1 which is incompatible.\n",
      "jupytercad 3.1.7 requires jupyter-collaboration-ui<2,>=1, but you have jupyter-collaboration-ui 2.1.1 which is incompatible.\n",
      "jupytercad 3.1.7 requires jupyter-docprovider<2,>=1, but you have jupyter-docprovider 2.1.1 which is incompatible.\n",
      "jupytercad 3.1.7 requires jupyter-server-ydoc<2,>=1, but you have jupyter-server-ydoc 2.1.1 which is incompatible.\n",
      "opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 2.4.1 which is incompatible.\n",
      "gcsfs 2025.9.0 requires fsspec==2025.9.0, but you have fsspec 2026.1.0 which is incompatible.\n",
      "google-auth-oauthlib 1.0.0 requires google-auth>=2.15.0, but you have google-auth 1.25.0 which is incompatible.\n",
      "google-api-core 2.10.2 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 6.31.1 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed certifi-2026.1.4 charset_normalizer-3.4.4 filelock-3.20.3 fsspec-2026.1.0 hf-xet-1.2.0 huggingface-hub-0.36.0 idna-3.11 numpy-2.4.1 packaging-25.0 pyyaml-6.0.3 regex-2026.1.15 requests-2.32.5 tokenizers-0.13.3 tqdm-4.67.1 transformers-4.29.2 typing-extensions-4.15.0 urllib3-2.6.3\n",
      "Collecting tf-keras\n",
      "  Using cached tf_keras-2.20.1-py3-none-any.whl.metadata (1.8 kB)\n",
      "Requirement already satisfied: tensorflow<2.21,>=2.20 in /opt/micromamba/lib/python3.11/site-packages (from tf-keras) (2.20.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /opt/micromamba/lib/python3.11/site-packages (from tensorflow<2.21,>=2.20->tf-keras) (2.3.1)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /opt/micromamba/lib/python3.11/site-packages (from tensorflow<2.21,>=2.20->tf-keras) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in /opt/micromamba/lib/python3.11/site-packages (from tensorflow<2.21,>=2.20->tf-keras) (25.2.10)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /opt/micromamba/lib/python3.11/site-packages (from tensorflow<2.21,>=2.20->tf-keras) (0.6.0)\n",
      "Requirement already satisfied: google_pasta>=0.1.1 in /opt/micromamba/lib/python3.11/site-packages (from tensorflow<2.21,>=2.20->tf-keras) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /opt/micromamba/lib/python3.11/site-packages (from tensorflow<2.21,>=2.20->tf-keras) (18.1.1)\n",
      "Requirement already satisfied: opt_einsum>=2.3.2 in /opt/micromamba/lib/python3.11/site-packages (from tensorflow<2.21,>=2.20->tf-keras) (3.4.0)\n",
      "Requirement already satisfied: packaging in /opt/micromamba/lib/python3.11/site-packages (from tensorflow<2.21,>=2.20->tf-keras) (25.0)\n",
      "Requirement already satisfied: protobuf>=5.28.0 in /opt/micromamba/lib/python3.11/site-packages (from tensorflow<2.21,>=2.20->tf-keras) (6.31.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /opt/micromamba/lib/python3.11/site-packages (from tensorflow<2.21,>=2.20->tf-keras) (2.32.5)\n",
      "Requirement already satisfied: setuptools in /opt/micromamba/lib/python3.11/site-packages (from tensorflow<2.21,>=2.20->tf-keras) (80.9.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /opt/micromamba/lib/python3.11/site-packages (from tensorflow<2.21,>=2.20->tf-keras) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /opt/micromamba/lib/python3.11/site-packages (from tensorflow<2.21,>=2.20->tf-keras) (3.1.0)\n",
      "Requirement already satisfied: typing_extensions>=3.6.6 in /opt/micromamba/lib/python3.11/site-packages (from tensorflow<2.21,>=2.20->tf-keras) (4.15.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /opt/micromamba/lib/python3.11/site-packages (from tensorflow<2.21,>=2.20->tf-keras) (1.17.3)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/micromamba/lib/python3.11/site-packages (from tensorflow<2.21,>=2.20->tf-keras) (1.62.2)\n",
      "Requirement already satisfied: tensorboard~=2.20.0 in /opt/micromamba/lib/python3.11/site-packages (from tensorflow<2.21,>=2.20->tf-keras) (2.20.0)\n",
      "Requirement already satisfied: keras>=3.10.0 in /opt/micromamba/lib/python3.11/site-packages (from tensorflow<2.21,>=2.20->tf-keras) (3.11.3)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /opt/micromamba/lib/python3.11/site-packages (from tensorflow<2.21,>=2.20->tf-keras) (2.4.1)\n",
      "Requirement already satisfied: h5py>=3.11.0 in /opt/micromamba/lib/python3.11/site-packages (from tensorflow<2.21,>=2.20->tf-keras) (3.14.0)\n",
      "Requirement already satisfied: ml_dtypes<1.0.0,>=0.5.1 in /opt/micromamba/lib/python3.11/site-packages (from tensorflow<2.21,>=2.20->tf-keras) (0.5.3)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/micromamba/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow<2.21,>=2.20->tf-keras) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/micromamba/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow<2.21,>=2.20->tf-keras) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/micromamba/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow<2.21,>=2.20->tf-keras) (2.6.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/micromamba/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow<2.21,>=2.20->tf-keras) (2026.1.4)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/micromamba/lib/python3.11/site-packages (from tensorboard~=2.20.0->tensorflow<2.21,>=2.20->tf-keras) (3.9)\n",
      "Requirement already satisfied: pillow in /opt/micromamba/lib/python3.11/site-packages (from tensorboard~=2.20.0->tensorflow<2.21,>=2.20->tf-keras) (11.3.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/micromamba/lib/python3.11/site-packages (from tensorboard~=2.20.0->tensorflow<2.21,>=2.20->tf-keras) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /opt/micromamba/lib/python3.11/site-packages (from tensorboard~=2.20.0->tensorflow<2.21,>=2.20->tf-keras) (3.1.3)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /opt/micromamba/lib/python3.11/site-packages (from astunparse>=1.6.0->tensorflow<2.21,>=2.20->tf-keras) (0.45.1)\n",
      "Requirement already satisfied: rich in /opt/micromamba/lib/python3.11/site-packages (from keras>=3.10.0->tensorflow<2.21,>=2.20->tf-keras) (14.1.0)\n",
      "Requirement already satisfied: namex in /opt/micromamba/lib/python3.11/site-packages (from keras>=3.10.0->tensorflow<2.21,>=2.20->tf-keras) (0.1.0)\n",
      "Requirement already satisfied: optree in /opt/micromamba/lib/python3.11/site-packages (from keras>=3.10.0->tensorflow<2.21,>=2.20->tf-keras) (0.17.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /opt/micromamba/lib/python3.11/site-packages (from werkzeug>=1.0.1->tensorboard~=2.20.0->tensorflow<2.21,>=2.20->tf-keras) (3.0.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/micromamba/lib/python3.11/site-packages (from rich->keras>=3.10.0->tensorflow<2.21,>=2.20->tf-keras) (4.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/micromamba/lib/python3.11/site-packages (from rich->keras>=3.10.0->tensorflow<2.21,>=2.20->tf-keras) (2.19.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/micromamba/lib/python3.11/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.10.0->tensorflow<2.21,>=2.20->tf-keras) (0.1.2)\n",
      "Using cached tf_keras-2.20.1-py3-none-any.whl (1.7 MB)\n",
      "Installing collected packages: tf-keras\n",
      "Successfully installed tf-keras-2.20.1\n"
     ]
    }
   ],
   "source": [
    "!pip install numpy==1.26.3, torch==2.8.0, scikit-learn==1.6.1, pandas==2.3.3, matplotlib==3.9.4, transformers==4.29.2\n",
    "!pip install --upgrade accelerate\n",
    "!pip install transformers==4.29.2 --force-reinstall\n",
    "!pip install tf-keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8f2e755d-4751-430c-8a78-2dadb4e1b378",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2b3fe3df736f00b75d232607fd3120cd",
     "grade": false,
     "grade_id": "cell-7c4fd71d642a4b9b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "home = os.environ[\"HOME\"]\n",
    "python_imports = f\"{home}/shared/DLN-2025W/notebook-eeg/Lab_GPT_based_EEG_decoder\"\n",
    "cache_root = f\"{home}/shared/DLN-2025W/notebook-eeg/Lab_GPT_based_EEG_decoder/\"\n",
    "sys.path.append(python_imports)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b469e5b-8a9d-47c9-943e-7122b54b8890",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "revert": ""
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8251fbdd-abe0-4cc7-8199-acecf32dfb6f",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f7506b9600a9552d4b52e3e551b7b0a3",
     "grade": false,
     "grade_id": "cell-0eeeb3fddbbda044",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-15 15:02:11.554230: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/opt/micromamba/lib/python3.11/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/attr_value.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/opt/micromamba/lib/python3.11/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/tensor.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/opt/micromamba/lib/python3.11/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/resource_handle.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/opt/micromamba/lib/python3.11/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/tensor_shape.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/opt/micromamba/lib/python3.11/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/types.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/opt/micromamba/lib/python3.11/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/full_type.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/opt/micromamba/lib/python3.11/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/function.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/opt/micromamba/lib/python3.11/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/node_def.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/opt/micromamba/lib/python3.11/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/op_def.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/opt/micromamba/lib/python3.11/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/graph.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/opt/micromamba/lib/python3.11/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/graph_debug_info.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/opt/micromamba/lib/python3.11/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/versions.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/opt/micromamba/lib/python3.11/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/protobuf/config.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/opt/micromamba/lib/python3.11/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at xla/tsl/protobuf/coordination_config.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/opt/micromamba/lib/python3.11/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/cost_graph.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/opt/micromamba/lib/python3.11/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/step_stats.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/opt/micromamba/lib/python3.11/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/allocation_description.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/opt/micromamba/lib/python3.11/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/tensor_description.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/opt/micromamba/lib/python3.11/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/protobuf/cluster.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/opt/micromamba/lib/python3.11/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/protobuf/debug.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "import sys \n",
    "sys.path.insert(0,os.path.join(python_imports,'NeuroGPT_mini/') )\n",
    "from sklearn.metrics import balanced_accuracy_score, cohen_kappa_score, f1_score\n",
    "import random\n",
    "import json\n",
    "\n",
    "### Import related to Transformer model (from files located in /NeuroGPT directory)\n",
    "\n",
    "from encoder.conformer_braindecode import EEGConformer\n",
    "from decoder.make_decoder import make_decoder\n",
    "from embedder.make import make_embedder\n",
    "from trainer.make import make_trainer\n",
    "from trainer.base import Trainer\n",
    "from decoder.unembedder import make_unembedder\n",
    "import pandas as pd\n",
    "from typing import Dict\n",
    "from dataloader.MIdataset import MotorImageryDataset\n",
    "with open(os.path.join(python_imports,\"NeuroGPT_mini/config.json\"), \"r\", encoding=\"utf-8\") as f:\n",
    "    config = json.load(f)\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "388dcd80-dc20-4906-bce1-4b3f5601032e",
   "metadata": {
    "revert": "## Part 1 : Introduction and Motivation \n\nElectroencephalography (EEG) records the brain’s electrical activity using electrodes placed on the scalp. These signals reflect how different brain regions communicate and are widely used in neuroscience, medicine, and brain–computer interfaces (BCI). A BCI allows direct interaction between the brain and a computer by decoding EEG patterns into commands. It enables applications such as neuroprosthetic control, emotion recognition, or cognitive state monitoring.\n\n![EEG](../../../../shared/DLN-2025W/notebook-eeg/Lab_GPT_based_EEG_decoder//NeuroGPT_mini/EEG.png)\n\n*Figure: EEG recording*\n\nEEG signals are noisy, non-stationary, and highly individual, making robust decoding a challenging task. Deep learning has emerged as a powerful solution to this problem. Neural networks can automatically learn complex spatiotemporal features from raw EEG data, often more efficient than traditional handcrafted feature extraction methods. \n\nArchitectures inspired by natural language processing—such as transformers and GPT-based models—have shown remarkable ability to model long-range dependencies and sequential patterns in EEG signals, analogous to understanding contextual relationships in language."
   },
   "source": [
    "## Part 1 : Introduction and Motivation \n",
    "\n",
    "Electroencephalography (EEG) records the brain’s electrical activity using electrodes placed on the scalp. These signals reflect how different brain regions communicate and are widely used in neuroscience, medicine, and brain–computer interfaces (BCI). A BCI allows direct interaction between the brain and a computer by decoding EEG patterns into commands. It enables applications such as neuroprosthetic control, emotion recognition, or cognitive state monitoring.\n",
    "\n",
    "![EEG](../../../../shared/DLN-2025W/notebook-eeg/Lab_GPT_based_EEG_decoder//NeuroGPT_mini/EEG.png)\n",
    "\n",
    "*Figure: EEG recording*\n",
    "\n",
    "EEG signals are noisy, non-stationary, and highly individual, making robust decoding a challenging task. Deep learning has emerged as a powerful solution to this problem. Neural networks can automatically learn complex spatiotemporal features from raw EEG data, often more efficient than traditional handcrafted feature extraction methods. \n",
    "\n",
    "Architectures inspired by natural language processing—such as transformers and GPT-based models—have shown remarkable ability to model long-range dependencies and sequential patterns in EEG signals, analogous to understanding contextual relationships in language."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22ebab27-2a2e-46bf-93cf-62bdd3c1f91c",
   "metadata": {
    "revert": "## Part 2 : The Dataset"
   },
   "source": [
    "## Part 2 : The Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb7eea65-b601-4eb2-a411-c1951df9169f",
   "metadata": {
    "revert": "### Brain-Computer Interface\n\nThis dataset in part of a set of datasets recorded in 2008 for a BCI Competition. These competitions aims to compare performances of models on different tasks consisting in analysing non-invasive signals from the brain (here, EEGs) to translate them into commands for an external device. \nThis dataset is, more preciselly, a Motor-Imagery dataset : EEG signals were recorded while subjects were imaginating themselves moving a certain part of their body. Thus, the classification task aims to recorver which part of the body were the one imagined by the subject from his EEG signal. \n\n### Experimental Paradigm\n\nThis data set consists of EEG data from 9 subjects. The cue-based BCI paradigm consisted of the imagination of movement of : \n* left hand (class 1),\n* right hand (class 2),\n* both feet (class 3),\n* tongue (class 4).\n\nTwo sessions on different days were recorded for each subject. Each session is comprised of 6 runs separated by short breaks. One run consists of 48 trials (12 for each of the four possible classes), yielding a total of 288 trials per session."
   },
   "source": [
    "### Brain-Computer Interface\n",
    "\n",
    "This dataset in part of a set of datasets recorded in 2008 for a BCI Competition. These competitions aims to compare performances of models on different tasks consisting in analysing non-invasive signals from the brain (here, EEGs) to translate them into commands for an external device. \n",
    "This dataset is, more preciselly, a Motor-Imagery dataset : EEG signals were recorded while subjects were imaginating themselves moving a certain part of their body. Thus, the classification task aims to recorver which part of the body were the one imagined by the subject from his EEG signal. \n",
    "\n",
    "### Experimental Paradigm\n",
    "\n",
    "This data set consists of EEG data from 9 subjects. The cue-based BCI paradigm consisted of the imagination of movement of : \n",
    "* left hand (class 1),\n",
    "* right hand (class 2),\n",
    "* both feet (class 3),\n",
    "* tongue (class 4).\n",
    "\n",
    "Two sessions on different days were recorded for each subject. Each session is comprised of 6 runs separated by short breaks. One run consists of 48 trials (12 for each of the four possible classes), yielding a total of 288 trials per session."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b5df760-53df-4a67-970d-3e5764a92705",
   "metadata": {
    "revert": "### Exploring data format\n\nIn the dataset file `bciiv2a_eeg_npz` each file is named as `A01T.npz` or `A01E.npz`. each file contain all the EEG data for each subject. "
   },
   "source": [
    "### Exploring data format\n",
    "\n",
    "In the dataset file `bciiv2a_eeg_npz` each file is named as `A01T.npz` or `A01E.npz`. each file contain all the EEG data for each subject. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bfa7fdb7-7b44-4668-9888-654336805162",
   "metadata": {
    "revert": "\nconfig_path = {\"dst_data_path\" : os.path.join(python_imports, \"bciiv2a_eeg_npz/\"),\n         \"pretrained_model\" : os.path.join(python_imports, \"NeuroGPT_mini/pytorch_model.bin\"), \n         \"log_dir\" :os.path.join(python_imports,\"training_logs/\"})\n"
   },
   "outputs": [],
   "source": [
    "\n",
    "config_path = {\"dst_data_path\" : os.path.join(python_imports, \"bciiv2a_eeg_npz/\"),\n",
    "         \"pretrained_model\" : os.path.join(python_imports, \"NeuroGPT_mini/pytorch_model.bin\"), \n",
    "         \"log_dir\" :os.path.join(python_imports,\"training_logs/\")}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "23d9b32e-0a30-4395-9235-d1b4ebee16f3",
   "metadata": {
    "revert": "\n\n\n\n# Load the data of one subject and print the differents type of information contained in the .npz file\neeg_data = np.load(os.path.join(config_path['dst_data_path'],'A01E.npz')) \nprint(eeg_data.files) \n"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['s', 'etyp', 'epos', 'edur', 'artifacts']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "# Load the data of one subject and print the differents type of information contained in the .npz file\n",
    "eeg_data = np.load(os.path.join(config_path['dst_data_path'],'A01E.npz')) \n",
    "print(eeg_data.files) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "35913bd6-b807-430e-a700-635709090f9c",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "28d81812bc040307331e2cb75d30eb19",
     "grade": false,
     "grade_id": "cell-f67d3be38bc0a28c",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "revert": "# Explore the raw EEG signal : print the type of python object, the shape, and the 5 first time-points\n\n### eeg_shape = ?? \n# YOUR CODE HERE\nraise NotImplementedError()",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keys in the .npz file: KeysView(NpzFile '/home/jovyan/shared/DLN-2025W/notebook-eeg/Lab_GPT_based_EEG_decoder/bciiv2a_eeg_npz/A01E.npz' with keys: s, etyp, epos, edur, artifacts)\n",
      "Type of s: <class 'numpy.ndarray'>\n",
      "Shape of s: (687000, 25)\n",
      "First 5 of s: [[ 11.23046875 -27.24609375   6.10351562   4.8828125    2.05078125\n",
      "   -2.63671875   3.02734375   3.85742188   4.78515625   4.24804688\n",
      "    2.24609375  -4.00390625  -7.08007812   2.29492188   4.19921875\n",
      "    6.39648438   3.17382812  -1.02539062   5.71289062   5.859375\n",
      "    4.34570312   9.91210938   3.41796875  45.41015625 -12.6953125 ]\n",
      " [  9.5703125  -22.55859375   7.91015625   8.88671875   4.15039062\n",
      "    1.5625       4.98046875   7.27539062   6.8359375    7.6171875\n",
      "    3.7109375    0.48828125  -3.3203125    3.56445312   5.46875\n",
      "    7.6171875    5.12695312   1.12304688   5.41992188   7.08007812\n",
      "    6.68945312   6.49414062   3.90625     45.41015625 -11.71875   ]\n",
      " [ 10.69335938 -26.12304688   5.61523438   6.34765625   4.296875\n",
      "    0.29296875  -2.05078125   1.12304688   2.9296875    3.02734375\n",
      "    2.9296875   -1.46484375  -2.00195312  -3.66210938  -0.53710938\n",
      "    1.3671875    0.390625    -1.70898438  -4.15039062  -1.70898438\n",
      "    0.1953125   -3.61328125  10.7421875   52.24609375  -2.44140625]\n",
      " [  6.78710938 -27.97851562   1.90429688   0.73242188  -0.14648438\n",
      "   -5.61523438  -5.37109375  -6.25        -2.1484375   -3.61328125\n",
      "   -2.05078125  -7.6171875   -5.61523438 -11.08398438  -6.78710938\n",
      "   -5.90820312  -4.44335938  -5.6640625  -10.59570312  -9.13085938\n",
      "   -7.08007812 -12.15820312   5.37109375  49.8046875   -6.8359375 ]\n",
      " [ 13.62304688 -16.65039062   9.5703125   10.10742188   8.44726562\n",
      "    6.88476562   7.37304688   7.2265625    8.3984375    9.52148438\n",
      "    7.66601562   6.4453125    7.66601562   6.59179688   5.95703125\n",
      "    7.66601562   8.25195312   7.66601562   8.34960938   7.27539062\n",
      "    8.74023438  10.30273438  14.16015625  62.5          5.859375  ]]\n",
      "Type of etyp: <class 'numpy.ndarray'>\n",
      "Shape of etyp: (595, 1)\n",
      "First 5 of etyp: [[32766]\n",
      " [  276]\n",
      " [32766]\n",
      " [  277]\n",
      " [32766]]\n",
      "Type of epos: <class 'numpy.ndarray'>\n",
      "Shape of epos: (595, 1)\n",
      "First 5 of epos: [[    1]\n",
      " [    1]\n",
      " [34292]\n",
      " [34292]\n",
      " [68851]]\n",
      "Type of edur: <class 'numpy.ndarray'>\n",
      "Shape of edur: (595, 1)\n",
      "First 5 of edur: [[    0]\n",
      " [34290]\n",
      " [    0]\n",
      " [34558]\n",
      " [    0]]\n",
      "Type of artifacts: <class 'numpy.ndarray'>\n",
      "Shape of artifacts: (288, 1)\n",
      "First 5 of artifacts: [[0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]]\n"
     ]
    }
   ],
   "source": [
    "# Explore the raw EEG signal : print the type of python object, the shape, and the 5 first time-points\n",
    "\n",
    "### eeg_shape = ?? \n",
    "# YOUR CODE HERE\n",
    "\n",
    "keys = eeg_data.keys()\n",
    "print(\"Keys in the .npz file:\", keys)\n",
    "for key in keys:\n",
    "    array = eeg_data[key]  # Access the array corresponding to each key\n",
    "    print(f\"Type of {key}: {type(array)}\")\n",
    "    print(f\"Shape of {key}: {array.shape}\")\n",
    "    print(f\"First 5 of {key}: {(array[:5])}\")\n",
    "# raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b83597c-af37-451b-8e79-420bc248a44c",
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "jupyter": {
     "outputs_hidden": true
    },
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e57d92c5b942fb25baa73a1fe804d015",
     "grade": true,
     "grade_id": "cell-5461f604c3333250",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "01533b6c-b168-4236-8899-54e21954236d",
   "metadata": {
    "revert": "# Events during EEG recordings : Explore the position, the type and the duration of the events\n\n# About the position\n\nprint(\"Positions of the events in EEG signals : \")\nprint(type(eeg_data['epos']))\nprint(eeg_data['epos'].shape)\nprint(eeg_data['epos'][:10])"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positions of the events in EEG signals : \n",
      "<class 'numpy.ndarray'>\n",
      "(595, 1)\n",
      "[[     1]\n",
      " [     1]\n",
      " [ 34292]\n",
      " [ 34292]\n",
      " [ 68851]\n",
      " [ 68851]\n",
      " [105991]\n",
      " [106341]\n",
      " [106841]\n",
      " [108344]]\n"
     ]
    }
   ],
   "source": [
    "# Events during EEG recordings : Explore the position, the type and the duration of the events\n",
    "\n",
    "# About the position\n",
    "\n",
    "print(\"Positions of the events in EEG signals : \")\n",
    "print(type(eeg_data['epos']))\n",
    "print(eeg_data['epos'].shape)\n",
    "print(eeg_data['epos'][:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "931ca174-2555-4b35-aaea-57d8f835ecbf",
   "metadata": {
    "revert": "# About the type of events in EEG signals\nprint(\"Type of the events in EEG signals : \")\nprint(type(eeg_data['etyp']))\nprint(eeg_data['etyp'].shape)\nprint(eeg_data['etyp'][:10])"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type of the events in EEG signals : \n",
      "<class 'numpy.ndarray'>\n",
      "(595, 1)\n",
      "[[32766]\n",
      " [  276]\n",
      " [32766]\n",
      " [  277]\n",
      " [32766]\n",
      " [ 1072]\n",
      " [32766]\n",
      " [  768]\n",
      " [  783]\n",
      " [  768]]\n"
     ]
    }
   ],
   "source": [
    "# About the type of events in EEG signals\n",
    "print(\"Type of the events in EEG signals : \")\n",
    "print(type(eeg_data['etyp']))\n",
    "print(eeg_data['etyp'].shape)\n",
    "print(eeg_data['etyp'][:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "09041c22-01fc-4093-b055-679946fd423d",
   "metadata": {
    "revert": "#About the duration of the events in EEG signals\nprint(\"Duration of events in EEG signals :\")\nprint(type(eeg_data['edur']))\nprint(eeg_data['edur'].shape)\nprint(eeg_data['edur'][:10])"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duration of events in EEG signals :\n",
      "<class 'numpy.ndarray'>\n",
      "(595, 1)\n",
      "[[    0]\n",
      " [34290]\n",
      " [    0]\n",
      " [34558]\n",
      " [    0]\n",
      " [37139]\n",
      " [    0]\n",
      " [ 1875]\n",
      " [  313]\n",
      " [ 1875]]\n"
     ]
    }
   ],
   "source": [
    "#About the duration of the events in EEG signals\n",
    "print(\"Duration of events in EEG signals :\")\n",
    "print(type(eeg_data['edur']))\n",
    "print(eeg_data['edur'].shape)\n",
    "print(eeg_data['edur'][:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3de424d7-20ef-410b-b140-50790d497909",
   "metadata": {
    "revert": "### MotorImageryDataset Class Overview\n\n**However, the data in this previous shape are raw and not adapted to be used as inputs for our decoding model. Thus, we have to implement a DataLoader object.** \n\nThe `MotorImageryDataset` class provides a flexible interface to **load, preprocess, and format EEG data** for training or evaluating deep learning models.  \n\nIt extends PyTorch’s `Dataset` to efficiently handle EEG recordings of this dataset and have task-specific logic to manage event markers, labels, and trial segmentation.  \nIt automates:\n\n- Loading raw EEG `.npy` files containing multiple trials for each subject\n- Reordering channels into a consistent montage\n- Extracting trials based on event markers  \n- Segmenting (chunking) long EEG signals into smaller overlapping windows  \n- Normalizing signals  using z-score normalization per channel . This ensures each channel has zero mean and unit variance, stabilizing model training.\n- Applying spatial projection matrices to match pretrained model configurations  \n- Preparing inputs and attention masks suitable for transformer or GPT-based models\n"
   },
   "source": [
    "### MotorImageryDataset Class Overview\n",
    "\n",
    "**However, the data in this previous shape are raw and not adapted to be used as inputs for our decoding model. Thus, we have to implement a DataLoader object.** \n",
    "\n",
    "The `MotorImageryDataset` class provides a flexible interface to **load, preprocess, and format EEG data** for training or evaluating deep learning models.  \n",
    "\n",
    "It extends PyTorch’s `Dataset` to efficiently handle EEG recordings of this dataset and have task-specific logic to manage event markers, labels, and trial segmentation.  \n",
    "It automates:\n",
    "\n",
    "- Loading raw EEG `.npy` files containing multiple trials for each subject\n",
    "- Reordering channels into a consistent montage\n",
    "- Extracting trials based on event markers  \n",
    "- Segmenting (chunking) long EEG signals into smaller overlapping windows  \n",
    "- Normalizing signals  using z-score normalization per channel . This ensures each channel has zero mean and unit variance, stabilizing model training.\n",
    "- Applying spatial projection matrices to match pretrained model configurations  \n",
    "- Preparing inputs and attention masks suitable for transformer or GPT-based models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1dcc0d8f-6569-4306-971e-26dfbbe62233",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "abeb6b32b034dc5e276bd8a40845f353",
     "grade": false,
     "grade_id": "cell-f64e3d84de5ac14f",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "revert": "# Compute the dataset (train, test, validation) \ndownstream_path = config_path[\"dst_data_path\"]\nfilenames = sorted(os.listdir(downstream_path))[:18]\nprint(\"Files from all the subjects : \", filenames)\ntrain_folds = []\ntest_folds = []\n\nfor i in range(9):\n    train_files = filenames[0:i*2] + filenames[i*2+2:]\n    test_files = filenames[i*2 : i*2+2]\n\n\nprint(\"Train dataset : \")\nprint(train_files)\n\n\ntrain_dataset = MotorImageryDataset(train_files, root_path=downstream_path)\n\n\nprint(\"Test dataset :\")\nprint(test_files)\n\n# On the way, compute the test dataset as :\n\n## TO DO : instanciate a MotorImageryDataset object but with the testing files\n# test_dataset = ... \n# YOUR CODE HERE\nraise NotImplementedError()\n\nvalidation_dataset = test_dataset"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files from all the subjects :  ['A01E.npz', 'A01T.npz', 'A02E.npz', 'A02T.npz', 'A03E.npz', 'A03T.npz', 'A04E.npz', 'A04T.npz', 'A05E.npz', 'A05T.npz', 'A06E.npz', 'A06T.npz', 'A07E.npz', 'A07T.npz', 'A08E.npz', 'A08T.npz', 'A09E.npz', 'A09T.npz']\n",
      "Train dataset : \n",
      "['A01E.npz', 'A01T.npz', 'A02E.npz', 'A02T.npz', 'A03E.npz', 'A03T.npz', 'A04E.npz', 'A04T.npz', 'A05E.npz', 'A05T.npz', 'A06E.npz', 'A06T.npz', 'A07E.npz', 'A07T.npz', 'A08E.npz', 'A08T.npz']\n",
      "Number of subjects loaded:  16\n",
      "Test dataset :\n",
      "['A09E.npz', 'A09T.npz']\n",
      "Number of subjects loaded:  2\n"
     ]
    }
   ],
   "source": [
    "# Compute the dataset (train, test, validation) \n",
    "downstream_path = config_path[\"dst_data_path\"]\n",
    "filenames = sorted(os.listdir(downstream_path))[:18]\n",
    "print(\"Files from all the subjects : \", filenames)\n",
    "train_folds = []\n",
    "test_folds = []\n",
    "\n",
    "for i in range(9):\n",
    "    train_files = filenames[0:i*2] + filenames[i*2+2:]\n",
    "    test_files = filenames[i*2 : i*2+2]\n",
    "\n",
    "\n",
    "print(\"Train dataset : \")\n",
    "print(train_files)\n",
    "\n",
    "\n",
    "train_dataset = MotorImageryDataset(train_files, root_path=downstream_path)\n",
    "\n",
    "\n",
    "print(\"Test dataset :\")\n",
    "print(test_files)\n",
    "\n",
    "# On the way, compute the test dataset as :\n",
    "\n",
    "## TO DO : instanciate a MotorImageryDataset object but with the testing files\n",
    "# test_dataset = ... \n",
    "# YOUR CODE HERE\n",
    "test_dataset = MotorImageryDataset(test_files, root_path=downstream_path)\n",
    "# raise NotImplementedError()\n",
    "\n",
    "validation_dataset = test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8a3f18a-55af-43af-9eb3-e190cf15c289",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "revert": ""
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d6f3b945-fbe6-40a6-8c2a-1088c355cf95",
   "metadata": {
    "revert": "## Part 3 : Instanciate the GPT-based model \n\n**Neuro-GPT** framework is a model combining an **EEG encoder** and a **GPT-style decoder** to learn causal representations of brain activity.  \nIt uses a **two-stage training pipeline**:\n\n1. **Pre-training (Self-supervised CSM)** where the model learns general EEG representations without labels.\n2. **Fine-tuning (Supervised Decoding)** where the pre-trained model is adapted to labeled classification tasks.\n\n\n### Model Overview\n\n![NeuroGPT Model Architecture](../../../../shared/DLN-2025W/notebook-eeg/Lab_GPT_based_EEG_decoder/NeuroGPT_mini/NeuroGPT.png)\n\n*Figure: Overview of the Neuro-GPT architecture integrating EEG encoder, causal masking, and GPT modules.*\n\n\n### Stage 1 : Pre-training (CSM: Causal Sequence Masking)\n\n**This stage has already been made and is not performed in this notebook : instead you can find the pretrained weights of the model. It is a 'checkpoint' for the model : when these weights are loaded, the model recovers the information from the pre-training phase. Descrition of the Stage 1 is only informative**  \n\nIt learns general spatio-temporal representations of EEG signals through **self-supervised learning**, without requiring labels.\n\n1. EEG Encoder\n\n- The raw EEG signals are split into N temporal chunks:\n![](../../../../shared/DLN-2025W/notebook-eeg/Lab_GPT_based_EEG_decoder/NeuroGPT_mini/d1d2.png)\n- Each chunk is of dimention C x T , where:\n  -  C : number of EEG channels  \n  -  T : time samples in each chunk  \n\nEach chunk is processed through:\n- **Temporal Convolutions** → capture short-term temporal structure.  \n- **Spatial Convolutions** → learn inter-channel dependencies.  \n- **Self-Attention Layers** → integrate temporal context within the chunk.\n\nThe encoder outputs embeddings:\n![](../../../../shared/DLN-2025W/notebook-eeg/Lab_GPT_based_EEG_decoder/NeuroGPT_mini/HD1.png)\nwhere \\( H(\\cdot) \\) is the learned mapping from raw EEG to embedding space.\n\n2. Causal Masking (CSM Mechanism)\n\nTo pre-train the model, each embedding sequence is masked progressively to enforce causal prediction:\n\n\n\\begin{align*}\n\\{H(D_1), M, 0, \\ldots, 0\\} \\\\\n\\{H(D_1), H(D_2), M, 0, \\ldots, 0\\} \\\\\n\\vdots \\\\\n\\{H(D_1), H(D_2), \\ldots, H_{N-1}, M\\}\n\\end{align*}\n\n\nwhere:\n- \\( M \\): learnable mask token  \n- \\( 0 \\): zero-padding (no access to future tokens)\n\nEach masked sequence is used as input to the GPT decoder, which attempts to reconstruct the masked token.\nThe self-supervised loss encourages the model to predict masked embeddings using past context.\n\n![](../../../../shared/DLN-2025W/notebook-eeg/Lab_GPT_based_EEG_decoder/NeuroGPT_mini/causalMasking.png)\n\n*Figure: Causal Masking : for a sequence with four to-\nkens (chunks). The sequence is duplicated three times and\nprogressively is masked each duplicated sequence*\n\n3. GPT Decoder (Transformer)\n\n- A decoder-only transformer(GPT-style) processes the masked embeddings.  \n- Self-attention layers capture dependencies between EEG tokens over time.  \n- Unlike BERT (which uses bidirectional context), GPT predicts next tokens using only past information, ensuring temporal causality.\n\n**Wrap-Up** : the objective of the pre-training phase is Causal Reconstruction\n\n\n\n\n\n### Stage 2 : Fine-tuning (Decoding Training) --> What we are doing to do in the next parts of this notebook\n\n\nIt adapt the **pre-trained Neuro-GPT** (EEG encoder + GPT) to a **specific supervised EEG decoding task**, such as motor imagery or cognitive state classification.\n\n1. Load Pre-trained Weights \n   - Initialize the model with parameters obtained from CSM pre-training.\n\n2. Add a Classification Head\n   - On top of the encoder (or combined encoder-GPT output), attach a decoder head (e.g., MLP + softmax) to predict class labels.\n\n3. Fine-tune the Entire Network \n   - Optionally freeze lower encoder layers to retain learned representations.  \n   - Train using labeled EEG data with a **cross-entropy loss**.\n\n---\n\n- The pre-trained model provides context-aware EEG embeddings that already encode temporal and spatial dependencies.\n- Fine-tuning adapts these embeddings to task-specific discriminative features.\n- This significantly reduces labeled data requirements and improves downstream EEG decoding accuracy.\n\n---\n\n"
   },
   "source": [
    "## Part 3 : Instanciate the GPT-based model \n",
    "\n",
    "**Neuro-GPT** framework is a model combining an **EEG encoder** and a **GPT-style decoder** to learn causal representations of brain activity.  \n",
    "It uses a **two-stage training pipeline**:\n",
    "\n",
    "1. **Pre-training (Self-supervised CSM)** where the model learns general EEG representations without labels.\n",
    "2. **Fine-tuning (Supervised Decoding)** where the pre-trained model is adapted to labeled classification tasks.\n",
    "\n",
    "\n",
    "### Model Overview\n",
    "\n",
    "![NeuroGPT Model Architecture](../../../../shared/DLN-2025W/notebook-eeg/Lab_GPT_based_EEG_decoder/NeuroGPT_mini/NeuroGPT.png)\n",
    "\n",
    "*Figure: Overview of the Neuro-GPT architecture integrating EEG encoder, causal masking, and GPT modules.*\n",
    "\n",
    "\n",
    "### Stage 1 : Pre-training (CSM: Causal Sequence Masking)\n",
    "\n",
    "**This stage has already been made and is not performed in this notebook : instead you can find the pretrained weights of the model. It is a 'checkpoint' for the model : when these weights are loaded, the model recovers the information from the pre-training phase. Descrition of the Stage 1 is only informative**  \n",
    "\n",
    "It learns general spatio-temporal representations of EEG signals through **self-supervised learning**, without requiring labels.\n",
    "\n",
    "1. EEG Encoder\n",
    "\n",
    "- The raw EEG signals are split into N temporal chunks:\n",
    "![](../../../../shared/DLN-2025W/notebook-eeg/Lab_GPT_based_EEG_decoder/NeuroGPT_mini/d1d2.png)\n",
    "- Each chunk is of dimention C x T , where:\n",
    "  -  C : number of EEG channels  \n",
    "  -  T : time samples in each chunk  \n",
    "\n",
    "Each chunk is processed through:\n",
    "- **Temporal Convolutions** → capture short-term temporal structure.  \n",
    "- **Spatial Convolutions** → learn inter-channel dependencies.  \n",
    "- **Self-Attention Layers** → integrate temporal context within the chunk.\n",
    "\n",
    "The encoder outputs embeddings:\n",
    "![](../../../../shared/DLN-2025W/notebook-eeg/Lab_GPT_based_EEG_decoder/NeuroGPT_mini/HD1.png)\n",
    "where \\( H(\\cdot) \\) is the learned mapping from raw EEG to embedding space.\n",
    "\n",
    "2. Causal Masking (CSM Mechanism)\n",
    "\n",
    "To pre-train the model, each embedding sequence is masked progressively to enforce causal prediction:\n",
    "\n",
    "\n",
    "\\begin{align*}\n",
    "\\{H(D_1), M, 0, \\ldots, 0\\} \\\\\n",
    "\\{H(D_1), H(D_2), M, 0, \\ldots, 0\\} \\\\\n",
    "\\vdots \\\\\n",
    "\\{H(D_1), H(D_2), \\ldots, H_{N-1}, M\\}\n",
    "\\end{align*}\n",
    "\n",
    "\n",
    "where:\n",
    "- \\( M \\): learnable mask token  \n",
    "- \\( 0 \\): zero-padding (no access to future tokens)\n",
    "\n",
    "Each masked sequence is used as input to the GPT decoder, which attempts to reconstruct the masked token.\n",
    "The self-supervised loss encourages the model to predict masked embeddings using past context.\n",
    "\n",
    "![](../../../../shared/DLN-2025W/notebook-eeg/Lab_GPT_based_EEG_decoder/NeuroGPT_mini/causalMasking.png)\n",
    "\n",
    "*Figure: Causal Masking : for a sequence with four to-\n",
    "kens (chunks). The sequence is duplicated three times and\n",
    "progressively is masked each duplicated sequence*\n",
    "\n",
    "3. GPT Decoder (Transformer)\n",
    "\n",
    "- A decoder-only transformer(GPT-style) processes the masked embeddings.  \n",
    "- Self-attention layers capture dependencies between EEG tokens over time.  \n",
    "- Unlike BERT (which uses bidirectional context), GPT predicts next tokens using only past information, ensuring temporal causality.\n",
    "\n",
    "**Wrap-Up** : the objective of the pre-training phase is Causal Reconstruction\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### Stage 2 : Fine-tuning (Decoding Training) --> What we are doing to do in the next parts of this notebook\n",
    "\n",
    "\n",
    "It adapt the **pre-trained Neuro-GPT** (EEG encoder + GPT) to a **specific supervised EEG decoding task**, such as motor imagery or cognitive state classification.\n",
    "\n",
    "1. Load Pre-trained Weights \n",
    "   - Initialize the model with parameters obtained from CSM pre-training.\n",
    "\n",
    "2. Add a Classification Head\n",
    "   - On top of the encoder (or combined encoder-GPT output), attach a decoder head (e.g., MLP + softmax) to predict class labels.\n",
    "\n",
    "3. Fine-tune the Entire Network \n",
    "   - Optionally freeze lower encoder layers to retain learned representations.  \n",
    "   - Train using labeled EEG data with a **cross-entropy loss**.\n",
    "\n",
    "---\n",
    "\n",
    "- The pre-trained model provides context-aware EEG embeddings that already encode temporal and spatial dependencies.\n",
    "- Fine-tuning adapts these embeddings to task-specific discriminative features.\n",
    "- This significantly reduces labeled data requirements and improves downstream EEG decoding accuracy.\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17ce897b-c64d-4d56-9bb4-8d7c92d6277a",
   "metadata": {
    "revert": "### Overview on the Model class : "
   },
   "source": [
    "### Overview on the Model class : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ef7bfb23-9478-4539-8db0-88422f351668",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d7a65cdff651cc9eff126e2d530090d5",
     "grade": false,
     "grade_id": "cell-6752e96ff3340f58",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "class Model(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Create Model object from embedder, decoder,\n",
    "    and unembedder (if not None).\n",
    "\n",
    "    Args\n",
    "    ----\n",
    "    embedder: src.embedder.make_embedder\n",
    "        Instance of embedder class.\n",
    "    decoder: src.decoder.make_decoder\n",
    "        Instance of decoder class.\n",
    "    unembedder: src.unembedder.make_unembedder\n",
    "        Instance of unembedder class.\n",
    "        Only added to model if not None.\n",
    "\n",
    "    Methods\n",
    "    ----\n",
    "    forward(batch: Dict[str, torch.tensor])\n",
    "        Forward pass of model.\n",
    "    prep_batch(batch: Dict[str, torch.tensor])\n",
    "        Prepare batch for forward pass.\n",
    "    compute_loss(batch: Dict[str, torch.tensor])\n",
    "        Compute training loss.\n",
    "    from_pretrained(pretrained_path: str)\n",
    "        Load pretrained model from pretrained_path.\n",
    "        Needs to point to pytorch_model.bin file \n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        encoder: torch.nn.Module,\n",
    "        embedder: torch.nn.Module,\n",
    "        decoder: torch.nn.Module,\n",
    "        unembedder: torch.nn.Module = None\n",
    "        ) -> torch.nn.Module:\n",
    "        \n",
    "        super().__init__()\n",
    "        self.name = f'Embedder-{embedder.name}_Decoder-{decoder.name}'\n",
    "        self.encoder = encoder\n",
    "        self.embedder = embedder\n",
    "        self.decoder = decoder\n",
    "        self.unembedder = unembedder\n",
    "        self.is_decoding_mode = False\n",
    "        self.ft_only_encoder = False\n",
    "\n",
    "    def from_pretrained(\n",
    "        self,\n",
    "        pretrained_path: str\n",
    "        ) -> None:\n",
    "        \"\"\"Load pretrained model from pretrained_path.\n",
    "        Needs to point to pytorch_model.bin file.\n",
    "        \"\"\"\n",
    "        print(\n",
    "            f'Loading pretrained model from {pretrained_path}'\n",
    "        )\n",
    "\n",
    "        if next(self.parameters()).is_cuda:\n",
    "            pretrained = torch.load(pretrained_path)\n",
    "\n",
    "        else:\n",
    "            pretrained = torch.load(pretrained_path, map_location=torch.device('cpu'))\n",
    "        \n",
    "        for k in self.state_dict():\n",
    "            \n",
    "            if k in pretrained:\n",
    "                assert pretrained[k].shape == self.state_dict()[k].shape,\\\n",
    "                    f'{k} shape mismatch between pretrained model and current model '+\\\n",
    "                    f'{pretrained[k].shape} vs {self.state_dict()[k].shape}'\n",
    "        \n",
    "        for k in pretrained:     \n",
    "            if k not in self.state_dict():\n",
    "                warnings.warn(\n",
    "                    f'Warning: /!\\ Skipping {k} from {pretrained_path} '\\\n",
    "                    'because it is not part of the current model'\n",
    "                )\n",
    "\n",
    "        # we set strict=False, because we can be sure\n",
    "        # that all relevant keys are in pretrained\n",
    "        self.load_state_dict(pretrained, strict=False)\n",
    "        \n",
    "    def switch_ft_mode(self, ft_encoder_only=False):\n",
    "        self.ft_only_encoder = ft_encoder_only\n",
    "\n",
    "    def switch_decoding_mode(\n",
    "        self,\n",
    "        is_decoding_mode: bool = False,\n",
    "        num_decoding_classes: int = None\n",
    "        ) -> None:\n",
    "        \"\"\"Switch model to decoding model or back to training mode.\n",
    "        Necessary to adapt pre-trained models to downstream\n",
    "        decoding tasks.\n",
    "        \n",
    "        Args\n",
    "        ----\n",
    "        is_decoding_mode: bool\n",
    "            Whether to switch to decoding mode or not.\n",
    "        num_decoding_classes: int\n",
    "            Number of classes to use for decoding.    \n",
    "        \"\"\"\n",
    "        self.is_decoding_mode = is_decoding_mode\n",
    "        \n",
    "        self.embedder.switch_decoding_mode(is_decoding_mode=is_decoding_mode)\n",
    "        self.decoder.switch_decoding_mode(\n",
    "            is_decoding_mode=is_decoding_mode,\n",
    "            num_decoding_classes=num_decoding_classes\n",
    "        )\n",
    "\n",
    "    def compute_loss(\n",
    "        self,\n",
    "        batch: Dict[str, torch.tensor],\n",
    "        return_outputs: bool = False\n",
    "        ) -> Dict[str, torch.tensor]:\n",
    "        \"\"\"\n",
    "        Compute training loss, based on \n",
    "        embedder's training-style.\n",
    "\n",
    "        Args\n",
    "        ----\n",
    "        batch: Dict[str, torch.tensor]\n",
    "            Input batch (as generated by src.batcher)\n",
    "        return_outputs: bool\n",
    "            Whether to return outputs of forward pass\n",
    "            or not. If False, only loss is returned.\n",
    "\n",
    "        Returns\n",
    "        ----\n",
    "        losses: Dict[str, torch.tensor]\n",
    "            Training losses.\n",
    "        outputs: torch.tensor\n",
    "            Outputs of forward pass.\n",
    "        \"\"\"\n",
    "        (outputs, batch) = self.forward(\n",
    "            batch=batch,\n",
    "            return_batch=True\n",
    "        )\n",
    "        losses = self.embedder.loss(\n",
    "            batch=batch,\n",
    "            outputs=outputs\n",
    "        )\n",
    "\n",
    "        return (losses, outputs) if return_outputs else losses\n",
    "\n",
    "    def prep_batch(\n",
    "        self,\n",
    "        batch: Dict[str, torch.tensor]\n",
    "        ) -> Dict[str, torch.tensor]:\n",
    "        \"\"\"Prepare input batch for forward pass.\n",
    "        Calls src.embedder.prep_batch.\n",
    "        \n",
    "        Args\n",
    "        ----\n",
    "        batch: Dict[str, torch.tensor]\n",
    "            Input batch (as generated by src.batcher)\n",
    "        \"\"\"\n",
    "        return self.embedder.prep_batch(batch=dict(batch))\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        batch: Dict[str, torch.tensor],\n",
    "        prep_batch: bool = True,\n",
    "        return_batch: bool = False\n",
    "        ) -> torch.tensor:\n",
    "        \"\"\"\n",
    "        Forward pass of model.\n",
    "        \n",
    "        Args\n",
    "        ----\n",
    "        batch: Dict[str, torch.tensor]\n",
    "            Input batch (as generated by src.batcher)\n",
    "        prep_batch: bool\n",
    "            Whether to prep batch for forward pass\n",
    "            by calling self.embedder.prep_batch\n",
    "        return_batch: bool\n",
    "            Whether to return batch after forward pass\n",
    "            or not. If False, only outputs of forward pass\n",
    "            are returned.\n",
    "\n",
    "        Returns\n",
    "        ----\n",
    "        outputs: torch.tensor\n",
    "            Outputs of forward pass.\n",
    "        batch: Dict[str, torch.tensor]\n",
    "            Input batch (as returned by prep_batch, \n",
    "            if prep_batch is True)\n",
    "        \"\"\"\n",
    "        \n",
    "        if self.encoder is not None:\n",
    "            #before prep_batch masking and things, we need to first let the splitted chunks of raw input through the encoder\n",
    "            features = self.encoder(batch['inputs'])\n",
    "            #attempt for trying fine-tune only the encoder, but the encoder cannot combine information across chunks.\n",
    "            if self.is_decoding_mode and self.ft_only_encoder:\n",
    "                outputs={'outputs': features, 'decoding_logits': features}\n",
    "                return (outputs, batch) if return_batch else outputs\n",
    "\n",
    "            b, f1, f2 = features.size()\n",
    "            nchunks = batch['inputs'].size()[1]\n",
    "            batch['inputs'] = features.view(b//nchunks, nchunks, f1*f2)\n",
    "        \n",
    "        if prep_batch:\n",
    "            if len(batch['inputs'].size()) > 3:\n",
    "                bsize, chunk, chann, time = batch['inputs'].size() \n",
    "                batch['inputs'] = batch['inputs'].view(bsize, chunk, chann*time)\n",
    "            batch = self.prep_batch(batch=batch)\n",
    "            # batch['inputs_embeds'] = batch['inputs_embeds'].view(bsize, chunk, chann, time)\n",
    "            # print(\"preparing batch\")\n",
    "        else:\n",
    "            assert 'inputs_embeds' in batch, 'inputs_embeds not in batch'\n",
    "\n",
    "        # pdb.set_trace()\n",
    "        batch['inputs_embeds'] = self.embedder(batch=batch)\n",
    "        outputs = self.decoder(batch=batch)\n",
    "        \n",
    "        if self.unembedder is not None and not self.is_decoding_mode:\n",
    "            outputs['outputs'] = self.unembedder(inputs=outputs['outputs'])['outputs']\n",
    "\n",
    "        return (outputs, batch) if return_batch else outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9420d66-52c2-4eaa-8e1a-0e8c720e1727",
   "metadata": {
    "revert": "Q : The compute_loss() function of the Model call the loss of one of the submodule (encoder). By looking in the files of the model (you can find them in the `shared/DLN-2025W/notebook-eeg/Lab_GPT_based_EEG_decoder/NeuroGPT_mini/` directory of the server) tell witch loss function is used for the finetuning (corresponding to 'decoding' training mode). "
   },
   "source": [
    "Q : The compute_loss() function of the Model call the loss of one of the submodule (encoder). By looking in the files of the model (you can find them in the `shared/DLN-2025W/notebook-eeg/Lab_GPT_based_EEG_decoder/NeuroGPT_mini/` directory of the server) tell witch loss function is used for the finetuning (corresponding to 'decoding' training mode). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "885d8583-eafb-48cd-9782-e51c7dfc8c84",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d88b0a08fd9af02c498810a5b4b30452",
     "grade": false,
     "grade_id": "cell-a889f83e4add36e1",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "revert": "def make_model(model_config) : \n# Generate the model\n    \n    \n    ## Encoder\n    \n    if model_config[\"use_encoder\"] == True:\n        \n        chann_coords = None\n        encoder = EEGConformer(n_outputs=model_config[\"num_decoding_classes\"], n_chans=22, n_times=model_config['chunk_len'], ch_pos=chann_coords, is_decoding_mode=model_config[\"ft_only_encoder\"])\n        #calculates the output dimension of the encoder, which is the output of transformer layer.\n        model_config[\"parcellation_dim\"] = ((model_config['chunk_len'] - model_config['filter_time_length'] + 1 - model_config['pool_time_length']) // model_config['stride_avg_pool'] + 1) * model_config['n_filters_time']\n\n    else:\n        encoder = None\n        model_config[\"parcellation_dim\"] = model_config[\"chunk_len\"] * 22\n    \n    ## Embedder\n    \n    embedder = make_embedder(\n        training_style=model_config[\"training_style\"],\n        architecture=model_config[\"architecture\"],\n        in_dim=model_config[\"parcellation_dim\"], # flattened, channel x chunk length\n        embed_dim=model_config[\"embedding_dim\"],\n        num_hidden_layers=model_config[\"num_hidden_layers_embedding_model\"],\n        dropout=model_config[\"dropout\"],\n        n_positions=model_config[\"n_positions\"]\n    )\n    \n    ## Decoder\n    decoder = make_decoder(\n        architecture=model_config[\"architecture\"],\n        num_hidden_layers=model_config[\"num_hidden_layers\"],\n        embed_dim=model_config[\"embedding_dim\"],\n        num_attention_heads=model_config[\"num_attention_heads\"],\n        n_positions=model_config[\"n_positions\"],\n        intermediate_dim_factor=model_config[\"intermediate_dim_factor\"],\n        hidden_activation=model_config[\"hidden_activation\"],\n        dropout=model_config[\"dropout\"]\n    )\n   \n    \n    if model_config[\"embedding_dim\"] != model_config[\"parcellation_dim\"]:\n        unembedder = make_unembedder(\n            embed_dim=model_config[\"embedding_dim\"],\n            num_hidden_layers=model_config[\"num_hidden_layers_unembedding_model\"],\n            out_dim=model_config[\"parcellation_dim\"],\n            dropout=model_config[\"dropout\"],\n        )\n    else:\n        print(\"No Embedder and Unembedder!\")\n        unembedder = None\n    \n    \n    \n    model = Model(\n        encoder=encoder,\n        embedder=embedder,\n        decoder=decoder,\n        unembedder=unembedder\n    )\n    \n    if model_config[\"ft_only_encoder\"]:\n        model.switch_ft_mode(ft_encoder_only=True)\n    \n    if model_config[\"training_style\"] == 'decoding':\n        model.switch_decoding_mode(\n            is_decoding_mode=True,\n            num_decoding_classes=model_config[\"num_decoding_classes\"]\n        )\n    \n    if model_config[\"pretrained_model\"] is not None:\n        model.from_pretrained(model_config[\"pretrained_model\"])\n    \n    if model_config[\"freeze_embedder\"]:\n        for param in model.embedder.parameters():\n            param.requires_grad = False\n    \n    if model_config[\"freeze_decoder\"]:\n\n        ## TO DO : freeze the parameters of the decoder module :\n        # YOUR CODE HERE\n        raise NotImplementedError()\n    if model_config[\"freeze_encoder\"]:\n        for name, param in model.encoder.named_parameters():\n            if 'fc.' in name \\\n            or 'final_layer' in name:\n                continue\n            else:\n                param.requires_grad = False\n        print('Frozen Encoder : Only the two last layers will be trained')\n    \n    if 'freeze_decoder_without_pooler_heads' in model_config \\\n        and model_config[\"freeze_decoder_without_pooler_heads\"]:\n        for name, param in model.decoder.named_parameters():\n            if 'pooler_layer' in name \\\n            or 'decoding_head' in name \\\n            or 'is_next_head' in name:\n    \n\n                continue\n            else:\n                param.requires_grad = False\n    \n    if model_config[\"freeze_unembedder\"] and unembedder is not None:\n        for param in model.unembedder.parameters():\n            param.requires_grad = False\n    return model"
   },
   "outputs": [],
   "source": [
    "def make_model(model_config) : \n",
    "# Generate the model\n",
    "    \n",
    "    \n",
    "    ## Encoder\n",
    "    \n",
    "    if model_config[\"use_encoder\"] == True:\n",
    "        \n",
    "        chann_coords = None\n",
    "        encoder = EEGConformer(n_outputs=model_config[\"num_decoding_classes\"], n_chans=22, n_times=model_config['chunk_len'], ch_pos=chann_coords, is_decoding_mode=model_config[\"ft_only_encoder\"])\n",
    "        #calculates the output dimension of the encoder, which is the output of transformer layer.\n",
    "        model_config[\"parcellation_dim\"] = ((model_config['chunk_len'] - model_config['filter_time_length'] + 1 - model_config['pool_time_length']) // model_config['stride_avg_pool'] + 1) * model_config['n_filters_time']\n",
    "\n",
    "    else:\n",
    "        encoder = None\n",
    "        model_config[\"parcellation_dim\"] = model_config[\"chunk_len\"] * 22\n",
    "    \n",
    "    ## Embedder\n",
    "    \n",
    "    embedder = make_embedder(\n",
    "        training_style=model_config[\"training_style\"],\n",
    "        architecture=model_config[\"architecture\"],\n",
    "        in_dim=model_config[\"parcellation_dim\"], # flattened, channel x chunk length\n",
    "        embed_dim=model_config[\"embedding_dim\"],\n",
    "        num_hidden_layers=model_config[\"num_hidden_layers_embedding_model\"],\n",
    "        dropout=model_config[\"dropout\"],\n",
    "        n_positions=model_config[\"n_positions\"]\n",
    "    )\n",
    "    \n",
    "    ## Decoder\n",
    "    decoder = make_decoder(\n",
    "        architecture=model_config[\"architecture\"],\n",
    "        num_hidden_layers=model_config[\"num_hidden_layers\"],\n",
    "        embed_dim=model_config[\"embedding_dim\"],\n",
    "        num_attention_heads=model_config[\"num_attention_heads\"],\n",
    "        n_positions=model_config[\"n_positions\"],\n",
    "        intermediate_dim_factor=model_config[\"intermediate_dim_factor\"],\n",
    "        hidden_activation=model_config[\"hidden_activation\"],\n",
    "        dropout=model_config[\"dropout\"]\n",
    "    )\n",
    "   \n",
    "    \n",
    "    if model_config[\"embedding_dim\"] != model_config[\"parcellation_dim\"]:\n",
    "        unembedder = make_unembedder(\n",
    "            embed_dim=model_config[\"embedding_dim\"],\n",
    "            num_hidden_layers=model_config[\"num_hidden_layers_unembedding_model\"],\n",
    "            out_dim=model_config[\"parcellation_dim\"],\n",
    "            dropout=model_config[\"dropout\"],\n",
    "        )\n",
    "    else:\n",
    "        print(\"No Embedder and Unembedder!\")\n",
    "        unembedder = None\n",
    "    \n",
    "    \n",
    "    \n",
    "    model = Model(\n",
    "        encoder=encoder,\n",
    "        embedder=embedder,\n",
    "        decoder=decoder,\n",
    "        unembedder=unembedder\n",
    "    )\n",
    "    \n",
    "    if model_config[\"ft_only_encoder\"]:\n",
    "        model.switch_ft_mode(ft_encoder_only=True)\n",
    "    \n",
    "    if model_config[\"training_style\"] == 'decoding':\n",
    "        model.switch_decoding_mode(\n",
    "            is_decoding_mode=True,\n",
    "            num_decoding_classes=model_config[\"num_decoding_classes\"]\n",
    "        )\n",
    "    \n",
    "    if model_config[\"pretrained_model\"] is not None:\n",
    "        model.from_pretrained(model_config[\"pretrained_model\"])\n",
    "    \n",
    "    if model_config[\"freeze_embedder\"]:\n",
    "        for param in model.embedder.parameters():\n",
    "            param.requires_grad = False\n",
    "    \n",
    "    if model_config[\"freeze_decoder\"]:\n",
    "\n",
    "        ## TO DO : freeze the parameters of the decoder module :\n",
    "        # YOUR CODE HERE\n",
    "        for name, param in model.decoder.named_parameters():\n",
    "            if 'pooler_layer' in name or 'decoding_head' in name:\n",
    "                # Keep these layers trainable\n",
    "                continue\n",
    "            else:\n",
    "                param.requires_grad = False\n",
    "        # raise NotImplementedError()\n",
    "        \n",
    "    if model_config[\"freeze_encoder\"]:\n",
    "        for name, param in model.encoder.named_parameters():\n",
    "            if 'fc.' in name \\\n",
    "            or 'final_layer' in name:\n",
    "                continue\n",
    "            else:\n",
    "                param.requires_grad = False\n",
    "        print('Frozen Encoder : Only the two last layers will be trained')\n",
    "    \n",
    "    if 'freeze_decoder_without_pooler_heads' in model_config \\\n",
    "        and model_config[\"freeze_decoder_without_pooler_heads\"]:\n",
    "        for name, param in model.decoder.named_parameters():\n",
    "            if 'pooler_layer' in name \\\n",
    "            or 'decoding_head' in name \\\n",
    "            or 'is_next_head' in name:\n",
    "    \n",
    "\n",
    "                continue\n",
    "            else:\n",
    "                param.requires_grad = False\n",
    "    \n",
    "    if model_config[\"freeze_unembedder\"] and unembedder is not None:\n",
    "        for param in model.unembedder.parameters():\n",
    "            param.requires_grad = False\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e344cd2a-8af6-444e-a68f-61b83e77af12",
   "metadata": {
    "revert": "### Instantiation of one model "
   },
   "source": [
    "### Instantiation of one model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4ba285dd-907d-4c3d-808e-a619f28134c7",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "cb64026b1114d20a7fbac76cdb2e4fd3",
     "grade": false,
     "grade_id": "cell-8fd03b6cfaf78b1b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FC Layer for Classification created.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/shared/DLN-2025W/notebook-eeg/Lab_GPT_based_EEG_decoder/NeuroGPT_mini/encoder/base.py:178: UserWarning: LogSoftmax final layer will be removed! Please adjust your loss function accordingly (e.g. CrossEntropyLoss)!\n",
      "  warnings.warn(\"LogSoftmax final layer will be removed! \" +\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pretrained model from /home/jovyan/shared/DLN-2025W/notebook-eeg/Lab_GPT_based_EEG_decoder/NeuroGPT_mini/pytorch_model.bin\n"
     ]
    }
   ],
   "source": [
    "model_config = config\n",
    "\n",
    "## Some important parameters in the architecture of the model \n",
    "\n",
    "model_config['pretrained_model'] = config_path['pretrained_model'] # Path to the file containing pretrained weights of the model, if model_config['pretrained_model'] = None the model is not pretrained\n",
    "model_config['embedding_dim'] = 1024 # Dimension of the latent representations in the model\n",
    "model_config['num_hidden_layers_embedding_model']= 1 # Number of hidden layers in the GPT model \n",
    "model_config['num_hidden_layers_unembedding_model']= 1 # Number of hidden layers on the unembedding module \n",
    "model_config['num_hidden_layers']= 6  #Number of hidden layers in the encoder module\n",
    "model_config['filter_time_length']= 25 #Size of the kernel of the temporal convolution layer \n",
    "model_config['stride_avg_pool']= 15  # Stride size used in the average-pooling operation\n",
    "model_config[\"freeze_encoder\"] = False # Whether to freeze the encoder (True = no training on encoder parameters, only the classification layer)\n",
    "\n",
    "\n",
    "model = make_model(model_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8d6c4d82-6841-4747-85f6-08de8826de63",
   "metadata": {
    "revert": "print(model)",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model(\n",
      "  (encoder): EEGConformer(\n",
      "    (patch_embedding): _PatchEmbedding(\n",
      "      (shallownet): Sequential(\n",
      "        (0): Conv2d(1, 40, kernel_size=(1, 25), stride=(1, 1))\n",
      "        (1): Conv2d(40, 40, kernel_size=(22, 1), stride=(1, 1))\n",
      "        (2): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (3): ELU(alpha=1.0)\n",
      "        (4): AvgPool2d(kernel_size=(1, 75), stride=(1, 15), padding=0)\n",
      "        (5): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (projection): Sequential(\n",
      "        (0): Conv2d(40, 40, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): Rearrange('b d_model 1 seq -> b seq d_model')\n",
      "      )\n",
      "    )\n",
      "    (transformer): _TransformerEncoder(\n",
      "      (0): _TransformerEncoderBlock(\n",
      "        (0): _ResidualAdd(\n",
      "          (fn): Sequential(\n",
      "            (0): LayerNorm((40,), eps=1e-05, elementwise_affine=True)\n",
      "            (1): _MultiHeadAttention(\n",
      "              (keys): Linear(in_features=40, out_features=40, bias=True)\n",
      "              (queries): Linear(in_features=40, out_features=40, bias=True)\n",
      "              (values): Linear(in_features=40, out_features=40, bias=True)\n",
      "              (att_drop): Dropout(p=0.5, inplace=False)\n",
      "              (projection): Linear(in_features=40, out_features=40, bias=True)\n",
      "            )\n",
      "            (2): Dropout(p=0.5, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (1): _ResidualAdd(\n",
      "          (fn): Sequential(\n",
      "            (0): LayerNorm((40,), eps=1e-05, elementwise_affine=True)\n",
      "            (1): _FeedForwardBlock(\n",
      "              (0): Linear(in_features=40, out_features=160, bias=True)\n",
      "              (1): GELU(approximate='none')\n",
      "              (2): Dropout(p=0.5, inplace=False)\n",
      "              (3): Linear(in_features=160, out_features=40, bias=True)\n",
      "            )\n",
      "            (2): Dropout(p=0.5, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): _TransformerEncoderBlock(\n",
      "        (0): _ResidualAdd(\n",
      "          (fn): Sequential(\n",
      "            (0): LayerNorm((40,), eps=1e-05, elementwise_affine=True)\n",
      "            (1): _MultiHeadAttention(\n",
      "              (keys): Linear(in_features=40, out_features=40, bias=True)\n",
      "              (queries): Linear(in_features=40, out_features=40, bias=True)\n",
      "              (values): Linear(in_features=40, out_features=40, bias=True)\n",
      "              (att_drop): Dropout(p=0.5, inplace=False)\n",
      "              (projection): Linear(in_features=40, out_features=40, bias=True)\n",
      "            )\n",
      "            (2): Dropout(p=0.5, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (1): _ResidualAdd(\n",
      "          (fn): Sequential(\n",
      "            (0): LayerNorm((40,), eps=1e-05, elementwise_affine=True)\n",
      "            (1): _FeedForwardBlock(\n",
      "              (0): Linear(in_features=40, out_features=160, bias=True)\n",
      "              (1): GELU(approximate='none')\n",
      "              (2): Dropout(p=0.5, inplace=False)\n",
      "              (3): Linear(in_features=160, out_features=40, bias=True)\n",
      "            )\n",
      "            (2): Dropout(p=0.5, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (2): _TransformerEncoderBlock(\n",
      "        (0): _ResidualAdd(\n",
      "          (fn): Sequential(\n",
      "            (0): LayerNorm((40,), eps=1e-05, elementwise_affine=True)\n",
      "            (1): _MultiHeadAttention(\n",
      "              (keys): Linear(in_features=40, out_features=40, bias=True)\n",
      "              (queries): Linear(in_features=40, out_features=40, bias=True)\n",
      "              (values): Linear(in_features=40, out_features=40, bias=True)\n",
      "              (att_drop): Dropout(p=0.5, inplace=False)\n",
      "              (projection): Linear(in_features=40, out_features=40, bias=True)\n",
      "            )\n",
      "            (2): Dropout(p=0.5, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (1): _ResidualAdd(\n",
      "          (fn): Sequential(\n",
      "            (0): LayerNorm((40,), eps=1e-05, elementwise_affine=True)\n",
      "            (1): _FeedForwardBlock(\n",
      "              (0): Linear(in_features=40, out_features=160, bias=True)\n",
      "              (1): GELU(approximate='none')\n",
      "              (2): Dropout(p=0.5, inplace=False)\n",
      "              (3): Linear(in_features=160, out_features=40, bias=True)\n",
      "            )\n",
      "            (2): Dropout(p=0.5, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (3): _TransformerEncoderBlock(\n",
      "        (0): _ResidualAdd(\n",
      "          (fn): Sequential(\n",
      "            (0): LayerNorm((40,), eps=1e-05, elementwise_affine=True)\n",
      "            (1): _MultiHeadAttention(\n",
      "              (keys): Linear(in_features=40, out_features=40, bias=True)\n",
      "              (queries): Linear(in_features=40, out_features=40, bias=True)\n",
      "              (values): Linear(in_features=40, out_features=40, bias=True)\n",
      "              (att_drop): Dropout(p=0.5, inplace=False)\n",
      "              (projection): Linear(in_features=40, out_features=40, bias=True)\n",
      "            )\n",
      "            (2): Dropout(p=0.5, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (1): _ResidualAdd(\n",
      "          (fn): Sequential(\n",
      "            (0): LayerNorm((40,), eps=1e-05, elementwise_affine=True)\n",
      "            (1): _FeedForwardBlock(\n",
      "              (0): Linear(in_features=40, out_features=160, bias=True)\n",
      "              (1): GELU(approximate='none')\n",
      "              (2): Dropout(p=0.5, inplace=False)\n",
      "              (3): Linear(in_features=160, out_features=40, bias=True)\n",
      "            )\n",
      "            (2): Dropout(p=0.5, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (4): _TransformerEncoderBlock(\n",
      "        (0): _ResidualAdd(\n",
      "          (fn): Sequential(\n",
      "            (0): LayerNorm((40,), eps=1e-05, elementwise_affine=True)\n",
      "            (1): _MultiHeadAttention(\n",
      "              (keys): Linear(in_features=40, out_features=40, bias=True)\n",
      "              (queries): Linear(in_features=40, out_features=40, bias=True)\n",
      "              (values): Linear(in_features=40, out_features=40, bias=True)\n",
      "              (att_drop): Dropout(p=0.5, inplace=False)\n",
      "              (projection): Linear(in_features=40, out_features=40, bias=True)\n",
      "            )\n",
      "            (2): Dropout(p=0.5, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (1): _ResidualAdd(\n",
      "          (fn): Sequential(\n",
      "            (0): LayerNorm((40,), eps=1e-05, elementwise_affine=True)\n",
      "            (1): _FeedForwardBlock(\n",
      "              (0): Linear(in_features=40, out_features=160, bias=True)\n",
      "              (1): GELU(approximate='none')\n",
      "              (2): Dropout(p=0.5, inplace=False)\n",
      "              (3): Linear(in_features=160, out_features=40, bias=True)\n",
      "            )\n",
      "            (2): Dropout(p=0.5, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (5): _TransformerEncoderBlock(\n",
      "        (0): _ResidualAdd(\n",
      "          (fn): Sequential(\n",
      "            (0): LayerNorm((40,), eps=1e-05, elementwise_affine=True)\n",
      "            (1): _MultiHeadAttention(\n",
      "              (keys): Linear(in_features=40, out_features=40, bias=True)\n",
      "              (queries): Linear(in_features=40, out_features=40, bias=True)\n",
      "              (values): Linear(in_features=40, out_features=40, bias=True)\n",
      "              (att_drop): Dropout(p=0.5, inplace=False)\n",
      "              (projection): Linear(in_features=40, out_features=40, bias=True)\n",
      "            )\n",
      "            (2): Dropout(p=0.5, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (1): _ResidualAdd(\n",
      "          (fn): Sequential(\n",
      "            (0): LayerNorm((40,), eps=1e-05, elementwise_affine=True)\n",
      "            (1): _FeedForwardBlock(\n",
      "              (0): Linear(in_features=40, out_features=160, bias=True)\n",
      "              (1): GELU(approximate='none')\n",
      "              (2): Dropout(p=0.5, inplace=False)\n",
      "              (3): Linear(in_features=160, out_features=40, bias=True)\n",
      "            )\n",
      "            (2): Dropout(p=0.5, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (fc): _FullyConnected(\n",
      "      (fc): Sequential(\n",
      "        (0): Linear(in_features=2160, out_features=256, bias=True)\n",
      "        (1): ELU(alpha=1.0)\n",
      "        (2): Dropout(p=0.5, inplace=False)\n",
      "        (3): Linear(in_features=256, out_features=32, bias=True)\n",
      "        (4): ELU(alpha=1.0)\n",
      "      )\n",
      "    )\n",
      "    (final_layer): _FinalLayer(\n",
      "      (final_layer): Sequential(\n",
      "        (0): Linear(in_features=32, out_features=4, bias=True)\n",
      "        (classification): LogSoftmax(dim=1)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (embedder): CSMEmbedder(\n",
      "    (xe_loss): CrossEntropyLoss()\n",
      "    (bxe_loss): BCEWithLogitsLoss()\n",
      "    (l1_loss): L1Loss()\n",
      "    (l2_loss): MSELoss()\n",
      "    (embed_model): EmbeddingModel(\n",
      "      (model): Sequential(\n",
      "        (0): Linear(in_features=1080, out_features=1024, bias=True)\n",
      "        (1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        (2): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (decoder): GPTModel(\n",
      "    (mse_loss): MSELoss()\n",
      "    (bxe_loss): BCEWithLogitsLoss()\n",
      "    (transformer): GPT2Model(\n",
      "      (wte): Embedding(1, 1024)\n",
      "      (wpe): Embedding(512, 1024)\n",
      "      (drop): Dropout(p=0.1, inplace=False)\n",
      "      (h): ModuleList(\n",
      "        (0-5): 6 x GPT2Block(\n",
      "          (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): GPT2Attention(\n",
      "            (c_attn): Conv1D()\n",
      "            (c_proj): Conv1D()\n",
      "            (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "            (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): GPT2MLP(\n",
      "            (c_fc): Conv1D()\n",
      "            (c_proj): Conv1D()\n",
      "            (act): NewGELUActivation()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (ln_f): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "    (pooler_layer): Sequential(\n",
      "      (0): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (1): Tanh()\n",
      "      (2): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (decoding_head): Sequential(\n",
      "      (0): Linear(in_features=1024, out_features=256, bias=True)\n",
      "      (1): ELU(alpha=1.0)\n",
      "      (2): Dropout(p=0.5, inplace=False)\n",
      "      (3): Linear(in_features=256, out_features=32, bias=True)\n",
      "      (4): ELU(alpha=1.0)\n",
      "      (5): Dropout(p=0.3, inplace=False)\n",
      "      (6): Linear(in_features=32, out_features=4, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (unembedder): UnEmbedder(\n",
      "    (model): Sequential(\n",
      "      (0): Linear(in_features=1024, out_features=1080, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbb7d6a6-3819-434a-a9c3-de80ed965529",
   "metadata": {
    "revert": "Q : In the first module of the model (ie the EEGConformer layer), the first two layers are Conv2d with different kernel shapes. Why do we use 2 different Convolutional layers for EEG data ?"
   },
   "source": [
    "Q : In the first module of the model (ie the EEGConformer layer), the first two layers are Conv2d with different kernel shapes. Why do we use 2 different Convolutional layers for EEG data ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f6dd6f8-ac29-4fbf-a849-125880111de3",
   "metadata": {
    "revert": "## Part 4 : Training the model\n\n### Custom Trainer Class\n\nWe use a custom `Trainer` class derived from Hugging Face’s `transformers.Trainer`.  \nIts purpose is to manage the full training loop of our EEG-classification model: creating dataloaders, running forward and backward passes, computing the loss, updating the model weights, and performing evaluation.  \n\nThis subclass adds behavior specific to our EEG pipeline. It customizes how training and evaluation dataloaders are built, ensuring correct batching. It also overrides `compute_loss()` so that loss computation is delegated to the model’s own `compute_loss()` method—allowing flexibility across different training styles (e.g., GPT-style decoding, autoencoding, contrastive setups). The `prediction_step()` method (that you can see if you dig into the codes) is adapted to return logits and labels in the format expected for EEG classification. \n\nIt takes as argument the training and the validation dataset and store the predictions made by the model in the directory `training_logs`. \n\nSee the HuggingFace transformers documentation for more details\n    on input arguments:\n    https://huggingface.co/transformers/main_classes/trainer.html"
   },
   "source": [
    "## Part 4 : Training the model\n",
    "\n",
    "### Custom Trainer Class\n",
    "\n",
    "We use a custom `Trainer` class derived from Hugging Face’s `transformers.Trainer`.  \n",
    "Its purpose is to manage the full training loop of our EEG-classification model: creating dataloaders, running forward and backward passes, computing the loss, updating the model weights, and performing evaluation.  \n",
    "\n",
    "This subclass adds behavior specific to our EEG pipeline. It customizes how training and evaluation dataloaders are built, ensuring correct batching. It also overrides `compute_loss()` so that loss computation is delegated to the model’s own `compute_loss()` method—allowing flexibility across different training styles (e.g., GPT-style decoding, autoencoding, contrastive setups). The `prediction_step()` method (that you can see if you dig into the codes) is adapted to return logits and labels in the format expected for EEG classification. \n",
    "\n",
    "It takes as argument the training and the validation dataset and store the predictions made by the model in the directory `training_logs`. \n",
    "\n",
    "See the HuggingFace transformers documentation for more details\n",
    "    on input arguments:\n",
    "    https://huggingface.co/transformers/main_classes/trainer.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3ca5e184-f3fd-4066-b63b-7371d5b0c7e3",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7c0ccd7f14e283a93330544265cd110f",
     "grade": false,
     "grade_id": "cell-6bd79a0c640d37d8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "trainer_config = config\n",
    "\n",
    "# Some important paramerter to build up the training stategy\n",
    "\n",
    "trainer_config['model_init'] = make_model # Function used to instanciate a model\n",
    "trainer_config['run_name'] = 'Finetunning_1' # Name of the run to save logs in a directory \n",
    "trainer_config['train_dataset'] = train_dataset \n",
    "trainer_config['validation_dataset'] = validation_dataset\n",
    "trainer_config['output_dir'] = os.path.join(config_path['log_dir'], trainer_config['run_name']) # Where to save training logs\n",
    "\n",
    "trainer_config['training_steps'] = 3000 # Number of training steps\n",
    "trainer_config['validation_steps'] = 500 # Number of validation steps\n",
    "# Whether to freeze the encoder (True = no training on encoder parameters)\n",
    "trainer_config['model_save_steps'] = config[\"training_steps\"]*2\n",
    "trainer_config['log_every_n_steps'] = 1000\n",
    "trainer_config['eval_every_n_steps'] = 500\n",
    "trainer_config['warmup_ratio'] = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e7fbf344-5ccb-444b-bfd8-ecd2b2ec5802",
   "metadata": {
    "revert": "\ntrainer = make_trainer(model_init=lambda: make_model(model_config), config = trainer_config) \n"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FC Layer for Classification created.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/shared/DLN-2025W/notebook-eeg/Lab_GPT_based_EEG_decoder/NeuroGPT_mini/encoder/base.py:178: UserWarning: LogSoftmax final layer will be removed! Please adjust your loss function accordingly (e.g. CrossEntropyLoss)!\n",
      "  warnings.warn(\"LogSoftmax final layer will be removed! \" +\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pretrained model from /home/jovyan/shared/DLN-2025W/notebook-eeg/Lab_GPT_based_EEG_decoder/NeuroGPT_mini/pytorch_model.bin\n"
     ]
    }
   ],
   "source": [
    "\n",
    "trainer = make_trainer(model_init=lambda: make_model(model_config), config = trainer_config) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3752b50f-2102-4b97-8f89-91f56423a77d",
   "metadata": {
    "revert": "trainer.train()\nprint(\"End of the training ! \")\ntrainer.save_model(os.path.join(config[\"log_dir\"], trainer_config['run_name'],\n                    'model_final'))"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FC Layer for Classification created.\n",
      "Loading pretrained model from /home/jovyan/shared/DLN-2025W/notebook-eeg/Lab_GPT_based_EEG_decoder/NeuroGPT_mini/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/micromamba/lib/python3.11/site-packages/transformers/optimization.py:407: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3000' max='3000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3000/3000 02:47, Epoch 41/42]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.408300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.973300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.693400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.610200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End of the training ! \n",
      "The model has been saved to :  training_logs/Finetunning_1/model_final\n"
     ]
    }
   ],
   "source": [
    "trainer.train()\n",
    "print(\"End of the training ! \")\n",
    "trainer.save_model(os.path.join(config[\"log_dir\"], trainer_config['run_name'],\n",
    "                    'model_final'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "401c1488-db16-4097-9948-7e424d043315",
   "metadata": {
    "revert": "## Part 4 : Evaluation of the performances of the model\n\nNow that the tricky part is done, we just have to assess the perfomance of the last-trained model. \nFor this, we use the function `trainer.predict()` implementing one inference of the test dataset on the model and saving the decoding outputs in the file `test_predictions.npy` as well as the ground truth in the file `test_label_ids.npy`. "
   },
   "source": [
    "## Part 4 : Evaluation of the performances of the model\n",
    "\n",
    "Now that the tricky part is done, we just have to assess the perfomance of the last-trained model. \n",
    "For this, we use the function `trainer.predict()` implementing one inference of the test dataset on the model and saving the decoding outputs in the file `test_predictions.npy` as well as the ground truth in the file `test_label_ids.npy`. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13069306-160a-4419-93e9-22e2ba85b84b",
   "metadata": {
    "revert": "### One function that make all at once "
   },
   "source": [
    "### One function that make all at once "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f35afa7f-a005-4b77-ac9e-62e720b7c69d",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "69692950a6a4d8feaaddc6b496a460a7",
     "grade": false,
     "grade_id": "cell-c679899cb40552cf",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def get_performance_from_trainer(trainer, test_dataset):\n",
    "    \"\"\"\n",
    "    This function takes as input a trainer that has already been trained \n",
    "    (So the the trainer.train() method must already been called on it)\n",
    "    And it returns the a dictionnary with the different performance metrics. \n",
    "    \"\"\"\n",
    "    test_prediction_ = trainer.predict(test_dataset)\n",
    "    test_preds = test_prediction_.predictions\n",
    "    test_labels = test_prediction_.label_ids\n",
    "    pred_label=np.argmax(test_preds, axis=1)\n",
    "\n",
    "    true_label = test_labels\n",
    "    pred_label = pred_label \n",
    "    balanced_acc = balanced_accuracy_score(true_label, pred_label)\n",
    "\n",
    "    kappa = cohen_kappa_score(true_label, pred_label)\n",
    "\n",
    "    weighted_f1 = f1_score(true_label, pred_label, average='weighted')\n",
    "\n",
    "    return {'Balanced Accuracy' : balanced_acc,\n",
    "           'Cohen s Kappa' : kappa, \n",
    "           'Weighted F1-score' : weighted_f1}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "951d3502-7f2d-415a-a922-6f481ee74233",
   "metadata": {
    "revert": "print(get_performance_from_trainer(trainer, test_dataset))"
   },
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Balanced Accuracy': np.float64(0.6388888888888888), 'Cohen s Kappa': np.float64(0.5185185185185186), 'Weighted F1-score': 0.6274524563795251}\n"
     ]
    }
   ],
   "source": [
    "print(get_performance_from_trainer(trainer, test_dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd156875-a6cb-413a-8745-0f40a179e893",
   "metadata": {
    "revert": "## Part 5 : Use this notebook as a sand-box : Comparing Model Performance Across Three Training Strategies\n\nIn this exercise, it's your turn to explore how pretraining and fine-tuning affect the performance of a GPT-based EEG classifier.  \nUsing the same training pipeline introduced previously, your goal is to evaluate the model under three different training configurations:\n\n\n1. **NPT_FT : Not Pretrained, Fully Fine-Tuned**  \n   - The model starts without any pretraining.  \n   - **All layers** are fine-tuned on the Motor Imagery dataset.\n\n2. **NPT_NFT : Not Pretrained, Only Last Layer Fine-Tuned**  \n   - The model starts without pretraining.  \n   - Only the **final classification layer** is fine-tuned; the rest of the model is frozen.\n\n3. **PT_FT : Pretrained and Fine-Tuned**  \n   - The model starts from a **pretrained checkpoint**.  \n   - All layers are fine-tuned on the downstream task.  \n   - This serves as the reference pretrained model.\n\nWhat You Need to Do\n\nFor **each of the three scenarios**:\n\n1. **Instantiate a new model** with the appropriate configuration (pretrained or not, layers frozen or not).  \n2. **Create a new `Trainer`** object with the correct parameters.  \n3. **Train the model** on the Motor Imagery dataset.  \n4. **Evaluate the model** on the test dataset using:  \n\n   `get_performance_from_trainer(trainer, test_dataset)`\n\n5. **Store the results** in three performance dictionaries:\n\n`perf_PT_FT`, `perf_NPT_FT`, `perf_NPT_NFT`\n\nExample structure:\n\nperf_PT_FT   = get_performance_from_trainer(trainer_PT_FT,   test_dataset)\nperf_NPT_FT  = get_performance_from_trainer(trainer_NPT_FT,  test_dataset)\nperf_NPT_NFT = get_performance_from_trainer(trainer_NPT_NFT, test_dataset)\n\nAfter computing perfomances for each training strategie, you'll be able to plot a figure similar to : \n![](../../../../shared/DLN-2025W/notebook-eeg/Lab_GPT_based_EEG_decoder/NeuroGPT_mini/perf_plot.png)\n\n"
   },
   "source": [
    "## Part 5 : Use this notebook as a sand-box : Comparing Model Performance Across Three Training Strategies\n",
    "\n",
    "In this exercise, it's your turn to explore how pretraining and fine-tuning affect the performance of a GPT-based EEG classifier.  \n",
    "Using the same training pipeline introduced previously, your goal is to evaluate the model under three different training configurations:\n",
    "\n",
    "\n",
    "1. **NPT_FT : Not Pretrained, Fully Fine-Tuned**  \n",
    "   - The model starts without any pretraining.  \n",
    "   - **All layers** are fine-tuned on the Motor Imagery dataset.\n",
    "\n",
    "2. **NPT_NFT : Not Pretrained, Only Last Layer Fine-Tuned**  \n",
    "   - The model starts without pretraining.  \n",
    "   - Only the **final classification layer** is fine-tuned; the rest of the model is frozen.\n",
    "\n",
    "3. **PT_FT : Pretrained and Fine-Tuned**  \n",
    "   - The model starts from a **pretrained checkpoint**.  \n",
    "   - All layers are fine-tuned on the downstream task.  \n",
    "   - This serves as the reference pretrained model.\n",
    "\n",
    "What You Need to Do\n",
    "\n",
    "For **each of the three scenarios**:\n",
    "\n",
    "1. **Instantiate a new model** with the appropriate configuration (pretrained or not, layers frozen or not).  \n",
    "2. **Create a new `Trainer`** object with the correct parameters.  \n",
    "3. **Train the model** on the Motor Imagery dataset.  \n",
    "4. **Evaluate the model** on the test dataset using:  \n",
    "\n",
    "   `get_performance_from_trainer(trainer, test_dataset)`\n",
    "\n",
    "5. **Store the results** in three performance dictionaries:\n",
    "\n",
    "`perf_PT_FT`, `perf_NPT_FT`, `perf_NPT_NFT`\n",
    "\n",
    "Example structure:\n",
    "\n",
    "perf_PT_FT   = get_performance_from_trainer(trainer_PT_FT,   test_dataset)\n",
    "perf_NPT_FT  = get_performance_from_trainer(trainer_NPT_FT,  test_dataset)\n",
    "perf_NPT_NFT = get_performance_from_trainer(trainer_NPT_NFT, test_dataset)\n",
    "\n",
    "After computing perfomances for each training strategie, you'll be able to plot a figure similar to : \n",
    "![](../../../../shared/DLN-2025W/notebook-eeg/Lab_GPT_based_EEG_decoder/NeuroGPT_mini/perf_plot.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7d74b38-a432-4254-b3c3-f5f1828b9efa",
   "metadata": {
    "revert": "## Model for comparing model performances\nThe goal is to compare : Model pretrained and finetuned (PT_FT), Model not pretrained and fine-tuned (NPT_FT), model with only the last layer fine-tuned (NPT_NFT).\n\n\n### Case 1 : Pretrained and Finetuned "
   },
   "source": [
    "## Model for comparing model performances\n",
    "The goal is to compare : Model pretrained and finetuned (PT_FT), Model not pretrained and fine-tuned (NPT_FT), model with only the last layer fine-tuned (NPT_NFT).\n",
    "\n",
    "\n",
    "### Case 1 : Pretrained and Finetuned "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1187bc9e-3f38-4e20-a30d-06868527fd8b",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d628fd88c135757d28d19f147a1b56cb",
     "grade": false,
     "grade_id": "cell-d005b117fbb9911e",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "revert": "# For the Pretrained and Finetuned model, nothing change in the model configuration \nmodel_config_PT_FT = config\n\n# TODO:\n# model_config_PT_FT['freeze_encoder'] = ????\n# model_config_PT_FT['pretrained_model'] = config_path['pretrained_model'] = ??????\n\n# YOUR CODE HERE\nraise NotImplementedError()\n\n# Instanciate the trainer \ntrainer_config_PT_FT = config \ntrainer_config_PT_FT['model_init'] = make_model\ntrainer_config_PT_FT['run_name'] = 'Finetune_PT_FT'\ntrainer_config_PT_FT['train_dataset'] = train_dataset\ntrainer_config_PT_FT['validation_dataset'] = validation_dataset\ntrainer_config_PT_FT['output_dir'] = os.path.join(config_path['log_dir'], trainer_config_PT_FT['run_name'])\ntrainer_config_PT_FT['training_steps'] = 3000\ntrainer_config_PT_FT['validation_steps'] = 500\ntrainer_config_PT_FT['weight_decay'] = 0.1\ntrainer_config_PT_FT['adam_beta1'] = 0.9\ntrainer_config_PT_FT['adam_beta2'] = 0.999\ntrainer_config_PT_FT['adam_epsilon'] = 1e-8\ntrainer_config_PT_FT['model_save_steps'] = trainer_config_PT_FT[\"training_steps\"]*2\ntrainer_config_PT_FT['log_every_n_steps'] = 1000\ntrainer_config_PT_FT['eval_every_n_steps'] = 500\ntrainer_config_PT_FT['warmup_ratio'] = 0.01\n\n\ntrainer_PT_FT = make_trainer(model_init=lambda: make_model(model_config_PT_FT), config = trainer_config_PT_FT)\ntrainer_PT_FT.train()\nprint(\"End of the training ! \")\ntrainer_PT_FT.save_model(os.path.join(config_path[\"log_dir\"], trainer_config_PT_FT['run_name'],\n                    'model_final'))\n# get the performances of the the model PT_FT\n\nperf_PT_FT = get_performance_from_trainer(trainer_PT_FT, test_dataset)\nprint('Performances of the Pretrained and Fine-tuned Model :', perf_PT_FT)"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FC Layer for Classification created.\n",
      "Loading pretrained model from /home/jovyan/shared/DLN-2025W/notebook-eeg/Lab_GPT_based_EEG_decoder/NeuroGPT_mini/pytorch_model.bin\n",
      "FC Layer for Classification created.\n",
      "Loading pretrained model from /home/jovyan/shared/DLN-2025W/notebook-eeg/Lab_GPT_based_EEG_decoder/NeuroGPT_mini/pytorch_model.bin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3000' max='3000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3000/3000 02:50, Epoch 41/42]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.408300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.973300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.693400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.610200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End of the training ! \n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performances of the Pretrained and Fine-tuned Model : {'Balanced Accuracy': np.float64(0.6388888888888888), 'Cohen s Kappa': np.float64(0.5185185185185186), 'Weighted F1-score': 0.6274524563795251}\n"
     ]
    }
   ],
   "source": [
    "# For the Pretrained and Finetuned model, nothing change in the model configuration \n",
    "model_config_PT_FT = config\n",
    "\n",
    "# TODO:\n",
    "# model_config_PT_FT['freeze_encoder'] = ????\n",
    "# model_config_PT_FT['pretrained_model'] = config_path['pretrained_model'] = ??????\n",
    "\n",
    "# YOUR CODE HERE\n",
    "model_config_PT_FT['pretrained_model'] = config_path['pretrained_model']\n",
    "model_config_PT_FT['freeze_encoder'] = False\n",
    "model_config_PT_FT['freeze_decoder'] = False\n",
    "model_config_PT_FT['freeze_embedder'] = False\n",
    "# raise NotImplementedError()\n",
    "\n",
    "# Instanciate the trainer \n",
    "trainer_config_PT_FT = config \n",
    "trainer_config_PT_FT['model_init'] = make_model\n",
    "trainer_config_PT_FT['run_name'] = 'Finetune_PT_FT'\n",
    "trainer_config_PT_FT['train_dataset'] = train_dataset\n",
    "trainer_config_PT_FT['validation_dataset'] = validation_dataset\n",
    "trainer_config_PT_FT['output_dir'] = os.path.join(config_path['log_dir'], trainer_config_PT_FT['run_name'])\n",
    "trainer_config_PT_FT['training_steps'] = 3000\n",
    "trainer_config_PT_FT['validation_steps'] = 500\n",
    "trainer_config_PT_FT['weight_decay'] = 0.1\n",
    "trainer_config_PT_FT['adam_beta1'] = 0.9\n",
    "trainer_config_PT_FT['adam_beta2'] = 0.999\n",
    "trainer_config_PT_FT['adam_epsilon'] = 1e-8\n",
    "trainer_config_PT_FT['model_save_steps'] = trainer_config_PT_FT[\"training_steps\"]*2\n",
    "trainer_config_PT_FT['log_every_n_steps'] = 1000\n",
    "trainer_config_PT_FT['eval_every_n_steps'] = 500\n",
    "trainer_config_PT_FT['warmup_ratio'] = 0.01\n",
    "\n",
    "\n",
    "trainer_PT_FT = make_trainer(model_init=lambda: make_model(model_config_PT_FT), config = trainer_config_PT_FT)\n",
    "trainer_PT_FT.train()\n",
    "print(\"End of the training ! \")\n",
    "# trainer_PT_FT.save_model(os.path.join(config_path[\"log_dir\"], trainer_config_PT_FT['run_name'],\n",
    "#                     'model_final'))\n",
    "# get the performances of the the model PT_FT\n",
    "\n",
    "perf_PT_FT = get_performance_from_trainer(trainer_PT_FT, test_dataset)\n",
    "print('Performances of the Pretrained and Fine-tuned Model :', perf_PT_FT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4b7feb4-0331-4b37-bc9d-4564d56ea04b",
   "metadata": {
    "revert": "## Case 2 : Not Pretrained and Fine-tuned "
   },
   "source": [
    "## Case 2 : Not Pretrained and Fine-tuned "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7b6a535b-0a13-4219-8f22-dac1cee10b60",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "38501d0a999f28caa8a0ad1a1dd5b9a6",
     "grade": false,
     "grade_id": "cell-021409e2572334d1",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "revert": "### You can look at the previous cell to be able to assess performances of the NOT PRETRAINED but FINE-TUNED model\n\nmodel_config_NPT_FT = config\n\n# TODO : Adapt the model parameters to the type of model you want to assess (hint : look at the explaination added when we defined model_config in the example pipeline )\n\n# model_config_NPT_FT['pretrained_model'] = ???\n# model_config_NPT_FT['freeze_encoder'] = ??? \n\n# YOUR CODE HERE\nraise NotImplementedError()\n\n# Instanciate the trainer \ntrainer_config_NPT_FT = config \ntrainer_config_NPT_FT['model_init'] = make_model\ntrainer_config_NPT_FT['run_name'] = 'Finetune_NPT_FT'\ntrainer_config_NPT_FT['train_dataset'] = train_dataset\ntrainer_config_NPT_FT['validation_dataset'] = validation_dataset\ntrainer_config_NPT_FT['output_dir'] = os.path.join(config_path['log_dir'], trainer_config_NPT_FT['run_name'])\ntrainer_config_NPT_FT['training_steps'] = 3000\ntrainer_config_NPT_FT['validation_steps'] = 500\ntrainer_config_NPT_FT['weight_decay'] = 0.1\ntrainer_config_NPT_FT['adam_beta1'] = 0.9\ntrainer_config_NPT_FT['adam_beta2'] = 0.999\ntrainer_config_NPT_FT['adam_epsilon'] = 1e-8\ntrainer_config_NPT_FT['model_save_steps'] = trainer_config_NPT_FT[\"training_steps\"]*2\ntrainer_config_NPT_FT['log_every_n_steps'] = 1000\ntrainer_config_NPT_FT['eval_every_n_steps'] = 500\ntrainer_config_NPT_FT['warmup_ratio'] = 0.01\n\n# TODO : compute perf_NPT_FT using the parameter defined above \n#perf_NPT_FT = ????\n\n# YOUR CODE HERE\nraise NotImplementedError()"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FC Layer for Classification created.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/shared/DLN-2025W/notebook-eeg/Lab_GPT_based_EEG_decoder/NeuroGPT_mini/encoder/base.py:178: UserWarning: LogSoftmax final layer will be removed! Please adjust your loss function accordingly (e.g. CrossEntropyLoss)!\n",
      "  warnings.warn(\"LogSoftmax final layer will be removed! \" +\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pretrained model from /home/jovyan/shared/DLN-2025W/notebook-eeg/Lab_GPT_based_EEG_decoder/NeuroGPT_mini/pytorch_model.bin\n",
      "FC Layer for Classification created.\n",
      "Loading pretrained model from /home/jovyan/shared/DLN-2025W/notebook-eeg/Lab_GPT_based_EEG_decoder/NeuroGPT_mini/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/micromamba/lib/python3.11/site-packages/transformers/optimization.py:407: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3000' max='3000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3000/3000 02:49, Epoch 41/42]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.408300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.973300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.693400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.610200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End of the training ! \n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "### You can look at the previous cell to be able to assess performances of the NOT PRETRAINED but FINE-TUNED model\n",
    "\n",
    "model_config_NPT_FT = config\n",
    "\n",
    "# TODO : Adapt the model parameters to the type of model you want to assess (hint : look at the explaination added when we defined model_config in the example pipeline )\n",
    "\n",
    "# model_config_NPT_FT['pretrained_model'] = ???\n",
    "# model_config_NPT_FT['freeze_encoder'] = ??? \n",
    "\n",
    "# YOUR CODE HERE\n",
    "model_config_PT_FT['pretrained_model'] = config_path['pretrained_model']\n",
    "model_config_PT_FT['freeze_encoder'] = False\n",
    "model_config_PT_FT['freeze_decoder'] = False\n",
    "model_config_PT_FT['freeze_embedder'] = False\n",
    "# raise NotImplementedError()\n",
    "\n",
    "# Instanciate the trainer \n",
    "trainer_config_NPT_FT = config \n",
    "trainer_config_NPT_FT['model_init'] = make_model\n",
    "trainer_config_NPT_FT['run_name'] = 'Finetune_NPT_FT'\n",
    "trainer_config_NPT_FT['train_dataset'] = train_dataset\n",
    "trainer_config_NPT_FT['validation_dataset'] = validation_dataset\n",
    "trainer_config_NPT_FT['output_dir'] = os.path.join(config_path['log_dir'], trainer_config_NPT_FT['run_name'])\n",
    "trainer_config_NPT_FT['training_steps'] = 3000\n",
    "trainer_config_NPT_FT['validation_steps'] = 500\n",
    "trainer_config_NPT_FT['weight_decay'] = 0.1\n",
    "trainer_config_NPT_FT['adam_beta1'] = 0.9\n",
    "trainer_config_NPT_FT['adam_beta2'] = 0.999\n",
    "trainer_config_NPT_FT['adam_epsilon'] = 1e-8\n",
    "trainer_config_NPT_FT['model_save_steps'] = trainer_config_NPT_FT[\"training_steps\"]*2\n",
    "trainer_config_NPT_FT['log_every_n_steps'] = 1000\n",
    "trainer_config_NPT_FT['eval_every_n_steps'] = 500\n",
    "trainer_config_NPT_FT['warmup_ratio'] = 0.01\n",
    "\n",
    "# TODO : compute perf_NPT_FT using the parameter defined above \n",
    "#perf_NPT_FT = ????\n",
    "\n",
    "# YOUR CODE HERE\n",
    "trainer_NPT_FT = make_trainer(model_init=lambda: make_model(model_config_NPT_FT), config = trainer_config_NPT_FT)\n",
    "trainer_NPT_FT.train()\n",
    "print(\"End of the training ! \")\n",
    "perf_NPT_FT = get_performance_from_trainer(trainer_NPT_FT, test_dataset)\n",
    "# raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afefc498-e158-466a-81cf-a3acd97a701b",
   "metadata": {
    "revert": "## Case 3 : Fine-tune only the last layer of the model "
   },
   "source": [
    "## Case 3 : Fine-tune only the last layer of the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ff19906f-4de4-429d-bee9-7af9c7474b68",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "81933ac4dc377b13624e654152affe15",
     "grade": false,
     "grade_id": "cell-0c6b05839e26fe66",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "revert": "### You can look at the previous cell to be able to assess performances of the NOT PRETRAINED model only fine-tuend on the last layer\n\nmodel_config_NPT_NFT = config\n\n## TO DO : Adapt the model parameters to the type of model you want to assess (hint : look at the explaination added when we defined model_config in the example pipeline )\n\n# model_config_NPT_NFT['pretrained_model'] = ???\n# model_config_NPT_NFT['freeze_encoder'] = ??? \n\n# YOUR CODE HERE\nraise NotImplementedError()\n\n# Instanciate the trainer \ntrainer_config_NPT_NFT = config \ntrainer_config_NPT_NFT['model_init'] = make_model\ntrainer_config_NPT_NFT['run_name'] = 'Finetune_NPT_NFT'\ntrainer_config_NPT_NFT['train_dataset'] = train_dataset\ntrainer_config_NPT_NFT['validation_dataset'] = validation_dataset\ntrainer_config_NPT_NFT['output_dir'] = os.path.join(config_path['log_dir'], trainer_config_NPT_NFT['run_name'])\ntrainer_config_NPT_NFT['training_steps'] = 3000\ntrainer_config_NPT_NFT['validation_steps'] = 500\ntrainer_config_NPT_NFT['weight_decay'] = 0.1\ntrainer_config_NPT_NFT['adam_beta1'] = 0.9\ntrainer_config_NPT_NFT['adam_beta2'] = 0.999\ntrainer_config_NPT_NFT['adam_epsilon'] = 1e-8\ntrainer_config_NPT_NFT['model_save_steps'] = trainer_config_NPT_NFT[\"training_steps\"]*2\ntrainer_config_NPT_NFT['log_every_n_steps'] = 1000\ntrainer_config_NPT_NFT['eval_every_n_steps'] = 500\ntrainer_config_NPT_NFT['warmup_ratio'] = 0.01\n\n# TODO : compute perf_NPT_FT using the parameter defined above \n#perf_NPT_NFT = ????\n\n# YOUR CODE HERE\nraise NotImplementedError()"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FC Layer for Classification created.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/shared/DLN-2025W/notebook-eeg/Lab_GPT_based_EEG_decoder/NeuroGPT_mini/encoder/base.py:178: UserWarning: LogSoftmax final layer will be removed! Please adjust your loss function accordingly (e.g. CrossEntropyLoss)!\n",
      "  warnings.warn(\"LogSoftmax final layer will be removed! \" +\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FC Layer for Classification created.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/micromamba/lib/python3.11/site-packages/transformers/optimization.py:407: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3000' max='3000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3000/3000 02:51, Epoch 41/42]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.495300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>1.108900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.909500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.840300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End of the training ! \n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "### You can look at the previous cell to be able to assess performances of the NOT PRETRAINED model only fine-tuend on the last layer\n",
    "\n",
    "model_config_NPT_NFT = config\n",
    "\n",
    "## TO DO : Adapt the model parameters to the type of model you want to assess (hint : look at the explaination added when we defined model_config in the example pipeline )\n",
    "\n",
    "# model_config_NPT_NFT['pretrained_model'] = ???\n",
    "# model_config_NPT_NFT['freeze_encoder'] = ??? \n",
    "\n",
    "# YOUR CODE HERE\n",
    "model_config_NPT_FT['pretrained_model'] = None\n",
    "model_config_NPT_FT['freeze_encoder'] = False\n",
    "model_config_NPT_FT['freeze_decoder'] = False\n",
    "model_config_NPT_FT['freeze_embedder'] = False\n",
    "# raise NotImplementedError()\n",
    "\n",
    "# Instanciate the trainer \n",
    "trainer_config_NPT_NFT = config \n",
    "trainer_config_NPT_NFT['model_init'] = make_model\n",
    "trainer_config_NPT_NFT['run_name'] = 'Finetune_NPT_NFT'\n",
    "trainer_config_NPT_NFT['train_dataset'] = train_dataset\n",
    "trainer_config_NPT_NFT['validation_dataset'] = validation_dataset\n",
    "trainer_config_NPT_NFT['output_dir'] = os.path.join(config_path['log_dir'], trainer_config_NPT_NFT['run_name'])\n",
    "trainer_config_NPT_NFT['training_steps'] = 3000\n",
    "trainer_config_NPT_NFT['validation_steps'] = 500\n",
    "trainer_config_NPT_NFT['weight_decay'] = 0.1\n",
    "trainer_config_NPT_NFT['adam_beta1'] = 0.9\n",
    "trainer_config_NPT_NFT['adam_beta2'] = 0.999\n",
    "trainer_config_NPT_NFT['adam_epsilon'] = 1e-8\n",
    "trainer_config_NPT_NFT['model_save_steps'] = trainer_config_NPT_NFT[\"training_steps\"]*2\n",
    "trainer_config_NPT_NFT['log_every_n_steps'] = 1000\n",
    "trainer_config_NPT_NFT['eval_every_n_steps'] = 500\n",
    "trainer_config_NPT_NFT['warmup_ratio'] = 0.01\n",
    "\n",
    "# TODO : compute perf_NPT_FT using the parameter defined above \n",
    "#perf_NPT_NFT = ????\n",
    "\n",
    "# YOUR CODE HERE\n",
    "trainer_NPT_NFT = make_trainer(model_init=lambda: make_model(model_config_NPT_NFT), config = trainer_config_NPT_NFT)\n",
    "trainer_NPT_NFT.train()\n",
    "print(\"End of the training ! \")\n",
    "perf_NPT_NFT = get_performance_from_trainer(trainer_NPT_NFT, test_dataset)\n",
    "# raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db2fdb61-724e-4247-a1ff-7131336c2128",
   "metadata": {
    "revert": "### Plot of the performances"
   },
   "source": [
    "### Plot of the performances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8c054c77-4c02-4b4a-81b5-7a8a25a8daac",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b35d952597490045988dedd745391065",
     "grade": false,
     "grade_id": "cell-f2d06327bb868225",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "models = [\"Pretrained and Fine-Tuned\", \"Not Pretrained but Fine-Tuned\", \"Not Pretrained with Frozen Encoder\"]\n",
    "\n",
    "# Extract metrics\n",
    "balanced_acc = [\n",
    "    perf_PT_FT['Balanced Accuracy'],\n",
    "    perf_NPT_FT['Balanced Accuracy'],\n",
    "    perf_NPT_NFT['Balanced Accuracy']\n",
    "]\n",
    "\n",
    "kappa = [\n",
    "    perf_PT_FT['Cohen s Kappa'],\n",
    "    perf_NPT_FT['Cohen s Kappa'],\n",
    "    perf_NPT_NFT['Cohen s Kappa']\n",
    "]\n",
    "\n",
    "weighted_f1 = [\n",
    "    perf_PT_FT['Weighted F1-score'],\n",
    "    perf_NPT_FT['Weighted F1-score'],\n",
    "    perf_NPT_NFT['Weighted F1-score']\n",
    "]\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(8,5))\n",
    "\n",
    "plt.plot(models, balanced_acc, marker='o', label=\"Balanced Accuracy\")\n",
    "plt.plot(models, kappa, marker='o', label=\"Cohen's Kappa\")\n",
    "plt.plot(models, weighted_f1, marker='o', label=\"Weighted F1-score\")\n",
    "\n",
    "plt.title(\"Model Performance Comparison\")\n",
    "plt.ylabel(\"Score\")\n",
    "plt.xlabel(\"Model\")\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3bf121d-357d-4d01-b29b-4d4916129092",
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "jupyter": {
     "outputs_hidden": true
    },
    "nbgrader": {
     "cell_type": "code",
     "checksum": "168215b6ca8a7de22f9949cb42f008ed",
     "grade": true,
     "grade_id": "cell-11e3c523411a6d54",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f80e1c0b-84ac-4ada-8db9-ee46ee4a835f",
   "metadata": {
    "revert": "## References"
   },
   "source": [
    "## References"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e313b748-8fa5-47a5-adba-712594083392",
   "metadata": {
    "revert": "NeuroGPT paper : https://arxiv.org/abs/2311.03764\n\nNeuroGPT GitHub (the code used in the notebook is derived from it but much simplified) : https://github.com/wenhui0206/NeuroGPT\n\nBCI Competition Datastet paper : https://www.bbci.de/competition/iv/desc_2a.pdf"
   },
   "source": [
    "NeuroGPT paper : https://arxiv.org/abs/2311.03764\n",
    "\n",
    "NeuroGPT GitHub (the code used in the notebook is derived from it but much simplified) : https://github.com/wenhui0206/NeuroGPT\n",
    "\n",
    "BCI Competition Datastet paper : https://www.bbci.de/competition/iv/desc_2a.pdf"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
